{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ea79405-3e58-4040-9d4b-79697654f227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch pandas torchvision scikit-learn tqdm kaggle timm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b990dab2-2199-4cc7-b547-bd3ad9a34014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mUnable to lock directory /var/lib/apt/lists/\u001b[0m\n",
      "\u001b[1;33mW: \u001b[0mProblem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\u001b[0m\n",
      "\u001b[1;33mW: \u001b[0mProblem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mUnable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!apt update -qq\n",
    "!apt install -qq unzip\n",
    "!unzip -q data.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6620ca06-f014-4cdb-a636-0f1de07297b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "data_root = \"data\"\n",
    "images_dir = os.path.join(data_root, \"images\")\n",
    "\n",
    "# Create images directory if it doesn't exist\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "\n",
    "# List to store image paths and labels\n",
    "dataset = []\n",
    "\n",
    "# Loop through each subfolder\n",
    "for subfolder in os.listdir(data_root):\n",
    "    subfolder_path = os.path.join(data_root, subfolder)\n",
    "\n",
    "    # Ensure it's a directory\n",
    "    if os.path.isdir(subfolder_path) and subfolder != \"images\":\n",
    "        # Loop through images inside the subfolder\n",
    "        for image in os.listdir(subfolder_path):\n",
    "            old_image_path = os.path.join(subfolder_path, image)\n",
    "\n",
    "            # Ensure it's a file (image)\n",
    "            if os.path.isfile(old_image_path):\n",
    "                # Define new image path in \"data/images\" directory\n",
    "                new_image_path = os.path.join(images_dir, image)\n",
    "\n",
    "                # If filename already exists, rename it to avoid conflicts\n",
    "                if os.path.exists(new_image_path):\n",
    "                    base, ext = os.path.splitext(image)\n",
    "                    counter = 1\n",
    "                    while os.path.exists(new_image_path):\n",
    "                        new_image_path = os.path.join(images_dir, f\"{base}_{counter}{ext}\")\n",
    "                        counter += 1\n",
    "\n",
    "                # Move image\n",
    "                shutil.move(old_image_path, new_image_path)\n",
    "\n",
    "                # Append to dataset with updated path and original label\n",
    "                dataset.append({\"image_path\": new_image_path, \"label\": subfolder})\n",
    "\n",
    "        # Optionally remove empty subfolder after moving images\n",
    "        os.rmdir(subfolder_path)\n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "df = df.rename(columns={\"image_path\": \"image_id\"})\n",
    "df[\"image_id\"] = df[\"image_id\"].str.replace(\"data/images/\", \"\", regex=False)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])\n",
    "\n",
    "df.to_csv(os.path.join(data_root, \"dataset.csv\"), index=False)\n",
    "\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "614b360e-ba07-4375-99b9-c2400c5e5072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the dataset again:\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a451a03-5a36-402a-b608-b9c09b038421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1722\n",
       "7    1194\n",
       "6     663\n",
       "5     652\n",
       "0     471\n",
       "3     346\n",
       "8     316\n",
       "2     314\n",
       "4     297\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f81fb4c6-d8a9-4472-b4c4-998d440bc51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    297\n",
      "4    297\n",
      "5    297\n",
      "6    297\n",
      "8    297\n",
      "2    297\n",
      "3    297\n",
      "7    297\n",
      "0    297\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you already have the DataFrame `df`\n",
    "# and that the column name is actually 'label'\n",
    "\n",
    "min_count = df['label'].value_counts().min()\n",
    "\n",
    "# Group by label and take a random sample of size min_count from each class\n",
    "df_balanced = df.groupby('label').sample(n=min_count, random_state=42)\n",
    "\n",
    "# Shuffle the resulting balanced dataset\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check new class distribution\n",
    "print(df_balanced['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1282e13-654a-4974-b4b9-3cf848b99bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from dataset import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2ba8c31-2cf8-4315-a109-bb206a542f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(df_balanced, test_size=0.2, random_state=42, stratify=df_balanced[\"label\"])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"label\"])\n",
    "\n",
    "# Change the path to the directory where the images are stored\n",
    "path = \"data/images\"\n",
    "train_dataset = Dataset(train_df, path)\n",
    "test_dataset = Dataset(test_df, path)\n",
    "val_dataset = Dataset(val_df, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4477227e-0b6d-4593-bbc3-da028ad14f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from model import SoyaTrans\n",
    "from train import Trainer\n",
    "\n",
    "batch_size = 16\n",
    "lr = 2e-4\n",
    "num_epochs = 35\n",
    "num_classes = 9\n",
    "\n",
    "\n",
    "def run_experiment(batch_size, lr):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = SoyaTrans(num_classes)\n",
    "    trainer = Trainer(model, train_loader, val_loader, test_loader, lr, num_epochs, batch_size=batch_size)\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.test()\n",
    "    torch.save(trainer.model.state_dict(), 'soyatrans.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "650ee9fc-d639-472f-879b-d6b3e1d17449",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/ubuntu/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:01<00:00, 352MB/s] \n",
      "/usr/lib/python3/dist-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ./aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Epoch 1/35: 100%|██████████| 134/134 [00:54<00:00,  2.47it/s, loss=1.8360]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 0\n",
      "Train Loss: 2.1097\n",
      "Test Loss: 1.9835\n",
      "Accuracy: 0.3895\n",
      "Precision: 0.3331\n",
      "Recall: 0.3895\n",
      "F1: 0.3316\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/35: 100%|██████████| 134/134 [00:52<00:00,  2.54it/s, loss=1.9321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Running experiment with batch_size=16, lr=0.0002\n",
      "Epoch: 1\n",
      "Train Loss: 1.9124\n",
      "Test Loss: 1.9049\n",
      "Accuracy: 0.4607\n",
      "Precision: 0.3953\n",
      "Recall: 0.4607\n",
      "F1: 0.3846\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/35: 100%|██████████| 134/134 [00:53<00:00,  2.52it/s, loss=1.8726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 2\n",
      "Train Loss: 1.8101\n",
      "Test Loss: 1.7798\n",
      "Accuracy: 0.5993\n",
      "Precision: 0.5926\n",
      "Recall: 0.5993\n",
      "F1: 0.5660\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/35: 100%|██████████| 134/134 [00:53<00:00,  2.52it/s, loss=1.8666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 3\n",
      "Train Loss: 1.7507\n",
      "Test Loss: 1.7447\n",
      "Accuracy: 0.6292\n",
      "Precision: 0.6654\n",
      "Recall: 0.6292\n",
      "F1: 0.6078\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/35: 100%|██████████| 134/134 [00:53<00:00,  2.51it/s, loss=1.5797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 4\n",
      "Train Loss: 1.7182\n",
      "Test Loss: 1.7219\n",
      "Accuracy: 0.6442\n",
      "Precision: 0.6483\n",
      "Recall: 0.6442\n",
      "F1: 0.6261\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/35: 100%|██████████| 134/134 [00:53<00:00,  2.51it/s, loss=1.8607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 5\n",
      "Train Loss: 1.7029\n",
      "Test Loss: 1.6966\n",
      "Accuracy: 0.6742\n",
      "Precision: 0.6822\n",
      "Recall: 0.6742\n",
      "F1: 0.6557\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/35: 100%|██████████| 134/134 [00:53<00:00,  2.49it/s, loss=1.9661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 6\n",
      "Train Loss: 1.6943\n",
      "Test Loss: 1.6861\n",
      "Accuracy: 0.6854\n",
      "Precision: 0.6901\n",
      "Recall: 0.6854\n",
      "F1: 0.6664\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/35: 100%|██████████| 134/134 [00:53<00:00,  2.48it/s, loss=1.4117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 7\n",
      "Train Loss: 1.6841\n",
      "Test Loss: 1.6697\n",
      "Accuracy: 0.7116\n",
      "Precision: 0.7253\n",
      "Recall: 0.7116\n",
      "F1: 0.6948\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/35: 100%|██████████| 134/134 [00:53<00:00,  2.48it/s, loss=1.5836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 8\n",
      "Train Loss: 1.6644\n",
      "Test Loss: 1.6549\n",
      "Accuracy: 0.7154\n",
      "Precision: 0.7221\n",
      "Recall: 0.7154\n",
      "F1: 0.6953\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/35: 100%|██████████| 134/134 [00:53<00:00,  2.51it/s, loss=1.7823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 9\n",
      "Train Loss: 1.6348\n",
      "Test Loss: 1.6449\n",
      "Accuracy: 0.7341\n",
      "Precision: 0.7784\n",
      "Recall: 0.7341\n",
      "F1: 0.7156\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/35: 100%|██████████| 134/134 [00:53<00:00,  2.50it/s, loss=1.3867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 10\n",
      "Train Loss: 1.5941\n",
      "Test Loss: 1.6311\n",
      "Accuracy: 0.7528\n",
      "Precision: 0.7848\n",
      "Recall: 0.7528\n",
      "F1: 0.7364\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/35: 100%|██████████| 134/134 [00:53<00:00,  2.49it/s, loss=1.8781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 11\n",
      "Train Loss: 1.5695\n",
      "Test Loss: 1.5713\n",
      "Accuracy: 0.8052\n",
      "Precision: 0.8274\n",
      "Recall: 0.8052\n",
      "F1: 0.7875\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/35: 100%|██████████| 134/134 [00:53<00:00,  2.49it/s, loss=1.7735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 12\n",
      "Train Loss: 1.5521\n",
      "Test Loss: 1.5668\n",
      "Accuracy: 0.8165\n",
      "Precision: 0.8384\n",
      "Recall: 0.8165\n",
      "F1: 0.8009\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/35: 100%|██████████| 134/134 [00:53<00:00,  2.49it/s, loss=1.5267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 13\n",
      "Train Loss: 1.5385\n",
      "Test Loss: 1.5539\n",
      "Accuracy: 0.8390\n",
      "Precision: 0.8428\n",
      "Recall: 0.8390\n",
      "F1: 0.8347\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/35: 100%|██████████| 134/134 [00:53<00:00,  2.49it/s, loss=1.3808]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 14\n",
      "Train Loss: 1.5298\n",
      "Test Loss: 1.5405\n",
      "Accuracy: 0.8390\n",
      "Precision: 0.8504\n",
      "Recall: 0.8390\n",
      "F1: 0.8336\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/35: 100%|██████████| 134/134 [00:53<00:00,  2.49it/s, loss=1.5500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 15\n",
      "Train Loss: 1.5246\n",
      "Test Loss: 1.5363\n",
      "Accuracy: 0.8464\n",
      "Precision: 0.8569\n",
      "Recall: 0.8464\n",
      "F1: 0.8393\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.| 78/134 [00:31<00:22,  2.49it/s, loss=1.4341]\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 23/35: 100%|██████████| 134/134 [00:54<00:00,  2.48it/s, loss=1.5730]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 22\n",
      "Train Loss: 1.5092\n",
      "Test Loss: 1.5153\n",
      "Accuracy: 0.8689\n",
      "Precision: 0.8765\n",
      "Recall: 0.8689\n",
      "F1: 0.8635\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/35: 100%|██████████| 134/134 [00:53<00:00,  2.49it/s, loss=1.3760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 23\n",
      "Train Loss: 1.5063\n",
      "Test Loss: 1.5122\n",
      "Accuracy: 0.8689\n",
      "Precision: 0.8684\n",
      "Recall: 0.8689\n",
      "F1: 0.8669\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/35: 100%|██████████| 134/134 [00:53<00:00,  2.48it/s, loss=1.4825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 24\n",
      "Train Loss: 1.5078\n",
      "Test Loss: 1.5099\n",
      "Accuracy: 0.8689\n",
      "Precision: 0.8705\n",
      "Recall: 0.8689\n",
      "F1: 0.8681\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/35: 100%|██████████| 134/134 [00:53<00:00,  2.49it/s, loss=1.7666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 25\n",
      "Train Loss: 1.5083\n",
      "Test Loss: 1.5152\n",
      "Accuracy: 0.8652\n",
      "Precision: 0.8706\n",
      "Recall: 0.8652\n",
      "F1: 0.8639\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/35: 100%|██████████| 134/134 [00:53<00:00,  2.50it/s, loss=1.3813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 26\n",
      "Train Loss: 1.5036\n",
      "Test Loss: 1.5151\n",
      "Accuracy: 0.8614\n",
      "Precision: 0.8619\n",
      "Recall: 0.8614\n",
      "F1: 0.8600\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/35: 100%|██████████| 134/134 [00:53<00:00,  2.51it/s, loss=1.8161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 27\n",
      "Train Loss: 1.5040\n",
      "Test Loss: 1.5117\n",
      "Accuracy: 0.8689\n",
      "Precision: 0.8686\n",
      "Recall: 0.8689\n",
      "F1: 0.8672\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/35: 100%|██████████| 134/134 [00:53<00:00,  2.50it/s, loss=1.4785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 28\n",
      "Train Loss: 1.5003\n",
      "Test Loss: 1.5104\n",
      "Accuracy: 0.8689\n",
      "Precision: 0.8710\n",
      "Recall: 0.8689\n",
      "F1: 0.8677\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/35: 100%|██████████| 134/134 [00:54<00:00,  2.47it/s, loss=1.5136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 29\n",
      "Train Loss: 1.4961\n",
      "Test Loss: 1.5124\n",
      "Accuracy: 0.8652\n",
      "Precision: 0.8661\n",
      "Recall: 0.8652\n",
      "F1: 0.8638\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/35: 100%|██████████| 134/134 [00:53<00:00,  2.49it/s, loss=1.5079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 30\n",
      "Train Loss: 1.4898\n",
      "Test Loss: 1.5109\n",
      "Accuracy: 0.8689\n",
      "Precision: 0.8703\n",
      "Recall: 0.8689\n",
      "F1: 0.8679\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/35: 100%|██████████| 134/134 [00:53<00:00,  2.51it/s, loss=1.4855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 31\n",
      "Train Loss: 1.4846\n",
      "Test Loss: 1.5049\n",
      "Accuracy: 0.8801\n",
      "Precision: 0.8845\n",
      "Recall: 0.8801\n",
      "F1: 0.8793\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/35: 100%|██████████| 134/134 [00:53<00:00,  2.49it/s, loss=1.6751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 32\n",
      "Train Loss: 1.4842\n",
      "Test Loss: 1.5088\n",
      "Accuracy: 0.8614\n",
      "Precision: 0.8611\n",
      "Recall: 0.8614\n",
      "F1: 0.8598\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/35: 100%|██████████| 134/134 [00:53<00:00,  2.50it/s, loss=1.4342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 33\n",
      "Train Loss: 1.4796\n",
      "Test Loss: 1.5062\n",
      "Accuracy: 0.8689\n",
      "Precision: 0.8679\n",
      "Recall: 0.8689\n",
      "F1: 0.8678\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/35: 100%|██████████| 134/134 [00:53<00:00,  2.50it/s, loss=1.3856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 34\n",
      "Train Loss: 1.4770\n",
      "Test Loss: 1.5035\n",
      "Accuracy: 0.8839\n",
      "Precision: 0.8826\n",
      "Recall: 0.8839\n",
      "F1: 0.8823\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Metrics:\n",
      "--------------------------------------------------\n",
      "Test Loss: 1.5035\n",
      "Accuracy: 0.8839\n",
      "Precision: 0.8826\n",
      "Recall: 0.8839\n",
      "F1: 0.8823\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# for batch_size, lr in itertools.product(batch_sizes, lrs):\n",
    "#     print(f\"\\nRunning experiment with batch_size={batch_size}, lr={lr}\")\n",
    "run_experiment(batch_size, lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ea79405-3e58-4040-9d4b-79697654f227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch pandas torchvision scikit-learn tqdm kaggle timm scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d482ea-0e22-4b07-a205-1d259fb90a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload kaggle.json first.\n",
    "!mkdir -p ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcab437-ab4b-4440-8f87-1e6810ed469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b990dab2-2199-4cc7-b547-bd3ad9a34014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt update -qq\n",
    "# !apt install -qq unzip\n",
    "# !kaggle datasets download nirmalsankalana/sugarcane-leaf-disease-dataset\n",
    "# !unzip -q sugarcane-leaf-disease-dataset.zip -d data\n",
    "# !kaggle datasets download  pungliyavithika/sugarcane-leaf-disease-classification\n",
    "!unzip -q sugarcane-leaf-disease-classification.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6620ca06-f014-4cdb-a636-0f1de07297b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {'Healthy': 0, 'RedRot': 1, 'RedRust': 2}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define base paths\n",
    "data_root = \"data\"\n",
    "images_dir = os.path.join(data_root, \"images\")\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "\n",
    "# Collect metadata for each image\n",
    "dataset = []\n",
    "\n",
    "for subfolder in os.listdir(data_root):\n",
    "    subfolder_path = os.path.join(data_root, subfolder)\n",
    "\n",
    "    # Skip non-directories and the images directory\n",
    "    if not os.path.isdir(subfolder_path) or subfolder == \"images\":\n",
    "        continue\n",
    "\n",
    "    for image in os.listdir(subfolder_path):\n",
    "        old_image_path = os.path.join(subfolder_path, image)\n",
    "\n",
    "        if os.path.isfile(old_image_path):\n",
    "            base, ext = os.path.splitext(image)\n",
    "            new_base = f\"{subfolder}_{base}\"\n",
    "            new_filename = f\"{new_base}{ext}\"\n",
    "            new_image_path = os.path.join(images_dir, new_filename)\n",
    "\n",
    "            # Ensure uniqueness\n",
    "            counter = 1\n",
    "            while os.path.exists(new_image_path):\n",
    "                new_filename = f\"{new_base}_{counter}{ext}\"\n",
    "                new_image_path = os.path.join(images_dir, new_filename)\n",
    "                counter += 1\n",
    "\n",
    "            # Move the file\n",
    "            shutil.move(old_image_path, new_image_path)\n",
    "\n",
    "            # Record the file metadata\n",
    "            dataset.append({\n",
    "                \"image_id\": new_filename,  # Just filename\n",
    "                \"label\": subfolder,\n",
    "                \"original_filename\": image\n",
    "            })\n",
    "\n",
    "    # Optionally remove the now-empty subfolder\n",
    "    os.rmdir(subfolder_path)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])\n",
    "\n",
    "# Save the dataset to CSV\n",
    "df.to_csv(os.path.join(data_root, \"dataset.csv\"), index=False)\n",
    "\n",
    "# Save label mapping\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label mapping:\", label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "614b360e-ba07-4375-99b9-c2400c5e5072",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3273/4177609947.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# To load the dataset again:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/workspace/data/dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# numpy compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m from pandas.compat import (\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mnp_version_under1p18\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_np_version_under1p18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_is_numpy_dev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m from pandas.compat.numpy import (\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mnp_array_datetime64_compat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/compat/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# numpy versioning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/util/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.util._decorators import (  # noqa\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mAppender\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mSubstitution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcache_readonly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcache_readonly\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/_libs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m from pandas._libs.tslibs import (\n\u001b[1;32m     15\u001b[0m     \u001b[0mNaT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/_libs/interval.pyx\u001b[0m in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "# To load the dataset again:\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/workspace/data/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a451a03-5a36-402a-b608-b9c09b038421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75\n",
       "2    75\n",
       "1    74\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1282e13-654a-4974-b4b9-3cf848b99bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from dataset import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2ba8c31-2cf8-4315-a109-bb206a542f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"label\"])\n",
    "\n",
    "# Change the path to the directory where the images are stored\n",
    "# RTC:data/images/RedRot_24.jpg\n",
    "path = \"data/images\"\n",
    "train_dataset = Dataset(train_df, path)\n",
    "test_dataset = Dataset(test_df, path)\n",
    "val_dataset = Dataset(val_df, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4477227e-0b6d-4593-bbc3-da028ad14f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/35: 100%|██████████| 23/23 [00:12<00:00,  1.90it/s, loss=1.1315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 0\n",
      "Train Loss: 1.1090\n",
      "Test Loss: 1.1035\n",
      "Accuracy: 0.3182\n",
      "Precision: 0.1012\n",
      "Recall: 0.3182\n",
      "F1: 0.1536\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/35: 100%|██████████| 23/23 [00:08<00:00,  2.80it/s, loss=1.1184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Running experiment with batch_size=8, lr=0.0002\n",
      "Epoch: 1\n",
      "Train Loss: 1.1132\n",
      "Test Loss: 1.0963\n",
      "Accuracy: 0.3182\n",
      "Precision: 0.1012\n",
      "Recall: 0.3182\n",
      "F1: 0.1536\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/35: 100%|██████████| 23/23 [00:08<00:00,  2.77it/s, loss=1.0887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 2\n",
      "Train Loss: 1.0983\n",
      "Test Loss: 1.0923\n",
      "Accuracy: 0.3182\n",
      "Precision: 0.1012\n",
      "Recall: 0.3182\n",
      "F1: 0.1536\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/35: 100%|██████████| 23/23 [00:08<00:00,  2.79it/s, loss=1.0923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 3\n",
      "Train Loss: 1.0925\n",
      "Test Loss: 1.0902\n",
      "Accuracy: 0.3182\n",
      "Precision: 0.1012\n",
      "Recall: 0.3182\n",
      "F1: 0.1536\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/35: 100%|██████████| 23/23 [00:08<00:00,  2.78it/s, loss=1.0893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 4\n",
      "Train Loss: 1.0927\n",
      "Test Loss: 1.0884\n",
      "Accuracy: 0.3636\n",
      "Precision: 0.3126\n",
      "Recall: 0.3636\n",
      "F1: 0.2741\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/35: 100%|██████████| 23/23 [00:08<00:00,  2.78it/s, loss=1.1101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 5\n",
      "Train Loss: 1.0925\n",
      "Test Loss: 1.0832\n",
      "Accuracy: 0.3182\n",
      "Precision: 0.1012\n",
      "Recall: 0.3182\n",
      "F1: 0.1536\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/35: 100%|██████████| 23/23 [00:08<00:00,  2.77it/s, loss=1.0900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 6\n",
      "Train Loss: 1.0853\n",
      "Test Loss: 1.0791\n",
      "Accuracy: 0.6818\n",
      "Precision: 0.4765\n",
      "Recall: 0.6818\n",
      "F1: 0.5577\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/35: 100%|██████████| 23/23 [00:08<00:00,  2.77it/s, loss=1.0728]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 7\n",
      "Train Loss: 1.0858\n",
      "Test Loss: 1.0740\n",
      "Accuracy: 0.4545\n",
      "Precision: 0.3668\n",
      "Recall: 0.4545\n",
      "F1: 0.3712\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/35: 100%|██████████| 23/23 [00:08<00:00,  2.76it/s, loss=1.0765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 8\n",
      "Train Loss: 1.0824\n",
      "Test Loss: 1.0768\n",
      "Accuracy: 0.4091\n",
      "Precision: 0.4750\n",
      "Recall: 0.4091\n",
      "F1: 0.3104\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/35: 100%|██████████| 23/23 [00:08<00:00,  2.76it/s, loss=1.0557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 9\n",
      "Train Loss: 1.0789\n",
      "Test Loss: 1.0667\n",
      "Accuracy: 0.7727\n",
      "Precision: 0.8439\n",
      "Recall: 0.7727\n",
      "F1: 0.7311\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/35: 100%|██████████| 23/23 [00:08<00:00,  2.77it/s, loss=1.0492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 10\n",
      "Train Loss: 1.0854\n",
      "Test Loss: 1.0655\n",
      "Accuracy: 0.6364\n",
      "Precision: 0.4667\n",
      "Recall: 0.6364\n",
      "F1: 0.5257\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/35: 100%|██████████| 23/23 [00:08<00:00,  2.76it/s, loss=1.0638]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 11\n",
      "Train Loss: 1.0729\n",
      "Test Loss: 1.0687\n",
      "Accuracy: 0.4091\n",
      "Precision: 0.2545\n",
      "Recall: 0.4091\n",
      "F1: 0.3133\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/35: 100%|██████████| 23/23 [00:08<00:00,  2.76it/s, loss=1.0961]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 12\n",
      "Train Loss: 1.0714\n",
      "Test Loss: 1.0623\n",
      "Accuracy: 0.6818\n",
      "Precision: 0.7614\n",
      "Recall: 0.6818\n",
      "F1: 0.6727\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/35: 100%|██████████| 23/23 [00:08<00:00,  2.75it/s, loss=1.0393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 13\n",
      "Train Loss: 1.0677\n",
      "Test Loss: 1.0632\n",
      "Accuracy: 0.6818\n",
      "Precision: 0.4652\n",
      "Recall: 0.6818\n",
      "F1: 0.5529\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/35: 100%|██████████| 23/23 [00:08<00:00,  2.75it/s, loss=1.0410]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 14\n",
      "Train Loss: 1.0642\n",
      "Test Loss: 1.0628\n",
      "Accuracy: 0.5000\n",
      "Precision: 0.6288\n",
      "Recall: 0.5000\n",
      "F1: 0.4648\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/35: 100%|██████████| 23/23 [00:08<00:00,  2.75it/s, loss=1.1793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 15\n",
      "Train Loss: 1.0747\n",
      "Test Loss: 1.0648\n",
      "Accuracy: 0.4091\n",
      "Precision: 0.2386\n",
      "Recall: 0.4091\n",
      "F1: 0.2970\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/35: 100%|██████████| 23/23 [00:08<00:00,  2.74it/s, loss=1.1428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 16\n",
      "Train Loss: 1.0678\n",
      "Test Loss: 1.0568\n",
      "Accuracy: 0.5000\n",
      "Precision: 0.4713\n",
      "Recall: 0.5000\n",
      "F1: 0.4064\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/35: 100%|██████████| 23/23 [00:08<00:00,  2.75it/s, loss=1.0549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 17\n",
      "Train Loss: 1.0542\n",
      "Test Loss: 1.0479\n",
      "Accuracy: 0.5455\n",
      "Precision: 0.4000\n",
      "Recall: 0.5455\n",
      "F1: 0.4463\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/35: 100%|██████████| 23/23 [00:08<00:00,  2.74it/s, loss=1.0299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 18\n",
      "Train Loss: 1.0601\n",
      "Test Loss: 1.0540\n",
      "Accuracy: 0.4545\n",
      "Precision: 0.3333\n",
      "Recall: 0.4545\n",
      "F1: 0.3719\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/35:  13%|█▎        | 3/23 [00:01<00:07,  2.67it/s, loss=1.0420]"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "from model import MaiaNet\n",
    "from train import Trainer\n",
    "\n",
    "num_epochs = 35\n",
    "num_classes = 3\n",
    "\n",
    "def run_experiment(batch_size, lr):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = MaiaNet(num_classes)\n",
    "    trainer = Trainer(model, train_loader, val_loader, test_loader, lr, num_epochs, batch_size=batch_size)\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.test()\n",
    "    # torch.save(trainer.model.state_dict())\n",
    "    torch.save(trainer.model.state_dict(), f\"maianet_bs{batch_size}_lr{lr}.pth\")\n",
    "\n",
    "batch_size = 8\n",
    "lr = 2e-4\n",
    "run_experiment(batch_size, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2fa8136-8581-4c8a-aeb6-a6c2a35f743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchcam -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1357a9d8-4858-4a9a-a7a5-10b12afb7e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaiaNet(\n",
       "  (head): HeadBlock(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (anti_aliasing_1): AntiAliasingBlock(\n",
       "    (block1): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (down_conversion): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): SiLU()\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (ma): MultiAttention(\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=4, bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=64, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (fca): MultiSpectralAttentionLayer(\n",
       "        (dct_layer): MultiSpectralDCTLayer()\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=4, bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=4, out_features=64, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ibn): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  )\n",
       "  (maia_1): MaiaBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (ma): MultiAttention(\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=16, bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=256, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (fca): MultiSpectralAttentionLayer(\n",
       "        (dct_layer): MultiSpectralDCTLayer()\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=16, bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=16, out_features=256, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ibn): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (residual_conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (anti_aliasing_2): AntiAliasingBlock(\n",
       "    (block1): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (down_conversion): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): SiLU()\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (ma): MultiAttention(\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=32, bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=512, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (fca): MultiSpectralAttentionLayer(\n",
       "        (dct_layer): MultiSpectralDCTLayer()\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=32, bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=512, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ibn): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (residual_conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "  )\n",
       "  (maia_2): MaiaBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (ma): MultiAttention(\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=32, bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=512, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (fca): MultiSpectralAttentionLayer(\n",
       "        (dct_layer): MultiSpectralDCTLayer()\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=32, bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=512, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ibn): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  )\n",
       "  (anti_aliasing_3): AntiAliasingBlock(\n",
       "    (block1): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (down_conversion): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "      (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): SiLU()\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (ma): MultiAttention(\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=64, bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=64, out_features=1024, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (fca): MultiSpectralAttentionLayer(\n",
       "        (dct_layer): MultiSpectralDCTLayer()\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=64, bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=64, out_features=1024, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ibn): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (residual_conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
       "  )\n",
       "  (maia_3): MaiaBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (ma): MultiAttention(\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=64, bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=64, out_features=1024, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (fca): MultiSpectralAttentionLayer(\n",
       "        (dct_layer): MultiSpectralDCTLayer()\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=64, bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=64, out_features=1024, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ibn): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  )\n",
       "  (maia_4): MaiaBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (ma): MultiAttention(\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=2048, out_features=128, bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=2048, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (fca): MultiSpectralAttentionLayer(\n",
       "        (dct_layer): MultiSpectralDCTLayer()\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=2048, out_features=128, bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=2048, bias=False)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ibn): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (residual_conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
       "  )\n",
       "  (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from model import MaiaNet \n",
    "model = MaiaNet(num_classes=3)\n",
    "\n",
    "state_dict = torch.load(\"maianet_bs8_lr0.0002.pth\", map_location=\"cpu\")\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ee98721-6973-49f7-8ec4-f26f88102887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maia_4.conv1.0 Conv2d(1024, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "maia_4.conv2.0 Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "maia_4.conv3.0 Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "maia_4.residual_conv Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d) and module.out_channels == 2048:\n",
    "        print(name, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c03cf8d-8b3b-4527-93f2-6fc4b118b767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.10/site-packages (1.26.4)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m134.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchcam 0.4.0 requires numpy<2.0.0,>=1.17.2, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9f08167-0007-4b24-954e-5887c7832bb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Matplotlib requires numpy>=1.23; you have 1.21.5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2954/1807731439.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethods\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradCAM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradCAMpp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScoreCAM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m \u001b[0m_check_versions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m_check_versions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             raise ImportError(f\"Matplotlib requires {modname}>={minver}; \"\n\u001b[0m\u001b[1;32m    261\u001b[0m                               f\"you have {module.__version__}\")\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Matplotlib requires numpy>=1.23; you have 1.21.5"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchcam.methods import GradCAM, GradCAMpp, ScoreCAM\n",
    "from torchcam.utils import overlay_mask\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your model is defined and loaded like this:\n",
    "from model import MaiaNet\n",
    "# from data import test_dataset  # Or any dataset with images\n",
    "\n",
    "# ----------------------\n",
    "# SETUP\n",
    "# ----------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MaiaNet(num_classes=3).to(device)\n",
    "model.load_state_dict(torch.load(\"maianet_bs16_lr0.0001.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# ----------------------\n",
    "# Choose the target layer\n",
    "# ----------------------\n",
    "# You need to know your model structure. This is an example:\n",
    "target_layer = \"maia_4.conv3.0\" # e.g., the last conv layer, adjust based on your model\n",
    "\n",
    "# ----------------------\n",
    "# Instantiate CAM methods\n",
    "# ----------------------\n",
    "cam_methods = {\n",
    "    \"Grad-CAM\": GradCAM(model, target_layer),\n",
    "    \"Grad-CAM++\": GradCAMpp(model, target_layer),\n",
    "    \"Score-CAM\": ScoreCAM(model, target_layer)\n",
    "}\n",
    "\n",
    "# Load one image from dataset\n",
    "img, label = train_dataset[0]\n",
    "# ----------------------\n",
    "# Inference and CAM computation\n",
    "# ----------------------\n",
    "outputs = model(input_tensor)\n",
    "pred_class = outputs.argmax(dim=1).item()\n",
    "\n",
    "# Compute and visualize CAMs\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, (name, cam) in enumerate(cam_methods.items()):\n",
    "    cam_map = cam(pred_class, outputs)  # This modifies internal state\n",
    "    heatmap = cam_map[0].cpu()  # [0] since batch_size = 1\n",
    "\n",
    "    # Overlay CAM on image\n",
    "    raw_img = transforms.ToPILImage()(input_tensor.squeeze().cpu())\n",
    "    overlayed = overlay_mask(raw_img, heatmap, alpha=0.5)\n",
    "\n",
    "    axs[i].imshow(overlayed)\n",
    "    axs[i].set_title(name)\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

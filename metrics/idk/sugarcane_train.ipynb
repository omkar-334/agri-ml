{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea79405-3e58-4040-9d4b-79697654f227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install torch pandas torchvision scikit-learn tqdm kaggle -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d482ea-0e22-4b07-a205-1d259fb90a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload kaggle.json first.\n",
    "!mkdir -p ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b990dab2-2199-4cc7-b547-bd3ad9a34014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Suggested packages:\n",
      "  zip\n",
      "The following NEW packages will be installed:\n",
      "  unzip\n",
      "0 upgraded, 1 newly installed, 0 to remove and 127 not upgraded.\n",
      "Need to get 175 kB of archives.\n",
      "After this operation, 386 kB of additional disk space will be used.\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package unzip.\n",
      "(Reading database ... 20729 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-26ubuntu3.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking unzip (6.0-26ubuntu3.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up unzip (6.0-26ubuntu3.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JDataset URL: https://www.kaggle.com/datasets/nirmalsankalana/sugarcane-leaf-disease-dataset\n",
      "License(s): CC0-1.0\n",
      "Downloading sugarcane-leaf-disease-dataset.zip to /workspace\n",
      " 93%|██████████████████████████████████████   | 148M/160M [00:02<00:00, 112MB/s]\n",
      "100%|████████████████████████████████████████| 160M/160M [00:02<00:00, 80.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "!apt update -qq\n",
    "!apt install -qq unzip\n",
    "!kaggle datasets download nirmalsankalana/sugarcane-leaf-disease-dataset\n",
    "!unzip -q sugarcane-leaf-disease-dataset.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6620ca06-f014-4cdb-a636-0f1de07297b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "data_root = \"data\"\n",
    "images_dir = os.path.join(data_root, \"images\")\n",
    "\n",
    "# Create images directory if it doesn't exist\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "\n",
    "# List to store image paths and labels\n",
    "dataset = []\n",
    "\n",
    "# Loop through each subfolder\n",
    "for subfolder in os.listdir(data_root):\n",
    "    subfolder_path = os.path.join(data_root, subfolder)\n",
    "\n",
    "    # Ensure it's a directory\n",
    "    if os.path.isdir(subfolder_path) and subfolder != \"images\":\n",
    "        # Loop through images inside the subfolder\n",
    "        for image in os.listdir(subfolder_path):\n",
    "            old_image_path = os.path.join(subfolder_path, image)\n",
    "\n",
    "            # Ensure it's a file (image)\n",
    "            if os.path.isfile(old_image_path):\n",
    "                # Define new image path in \"data/images\" directory\n",
    "                new_image_path = os.path.join(images_dir, image)\n",
    "\n",
    "                # If filename already exists, rename it to avoid conflicts\n",
    "                if os.path.exists(new_image_path):\n",
    "                    base, ext = os.path.splitext(image)\n",
    "                    counter = 1\n",
    "                    while os.path.exists(new_image_path):\n",
    "                        new_image_path = os.path.join(images_dir, f\"{base}_{counter}{ext}\")\n",
    "                        counter += 1\n",
    "\n",
    "                # Move image\n",
    "                shutil.move(old_image_path, new_image_path)\n",
    "\n",
    "                # Append to dataset with updated path and original label\n",
    "                dataset.append({\"image_path\": new_image_path, \"label\": subfolder})\n",
    "\n",
    "        # Optionally remove empty subfolder after moving images\n",
    "        os.rmdir(subfolder_path)\n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "df = df.rename(columns={\"image_path\": \"image_id\"})\n",
    "df[\"image_id\"] = df[\"image_id\"].str.replace(\"data/images/\", \"\", regex=False)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])\n",
    "\n",
    "df.to_csv(os.path.join(data_root, \"dataset.csv\"), index=False)\n",
    "\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "614b360e-ba07-4375-99b9-c2400c5e5072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the dataset again:\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/workspace/data1/dataset3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a451a03-5a36-402a-b608-b9c09b038421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    522\n",
       "2    518\n",
       "3    514\n",
       "4    505\n",
       "1    462\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1282e13-654a-4974-b4b9-3cf848b99bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from dataset import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2ba8c31-2cf8-4315-a109-bb206a542f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"label\"])\n",
    "\n",
    "# Change the path to the directory where the images are stored\n",
    "path = \"/workspace\"\n",
    "train_dataset = Dataset(train_df, path)\n",
    "test_dataset = Dataset(test_df, path)\n",
    "val_dataset = Dataset(val_df, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74835b67-d1c5-4afc-8dd3-41fca69aa88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.3697, 0.2860, 0.3159],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.4051, 0.3836, 0.4274],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.4732, 0.5311, 0.6120],\n",
       "          ...,\n",
       "          [0.3315, 0.2916, 0.2550,  ..., 0.2480, 0.1837, 0.1911],\n",
       "          [0.2646, 0.2746, 0.2504,  ..., 0.2729, 0.1733, 0.0865],\n",
       "          [0.2399, 0.1785, 0.1543,  ..., 0.4887, 0.3729, 0.1246]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.2494, 0.3146, 0.2992],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.3173, 0.4177, 0.4482],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.4257, 0.5152, 0.5343],\n",
       "          ...,\n",
       "          [0.4353, 0.2979, 0.2925,  ..., 0.1632, 0.1958, 0.2245],\n",
       "          [0.2591, 0.2390, 0.1742,  ..., 0.4401, 0.1934, 0.2454],\n",
       "          [0.2574, 0.1692, 0.1294,  ..., 0.4937, 0.3558, 0.2810]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.2207, 0.2100, 0.1957],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.2794, 0.4223, 0.2720],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.3051, 0.4364, 0.3306],\n",
       "          ...,\n",
       "          [0.2353, 0.1880, 0.1902,  ..., 0.2770, 0.1476, 0.1566],\n",
       "          [0.2479, 0.1271, 0.1515,  ..., 0.3261, 0.2108, 0.1970],\n",
       "          [0.2029, 0.1259, 0.1368,  ..., 0.5674, 0.2630, 0.2341]]]),\n",
       " 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4477227e-0b6d-4593-bbc3-da028ad14f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from model import MaiaNet\n",
    "from train import Trainer\n",
    "\n",
    "batch_sizes = [32, 16, 12, 8, 4]\n",
    "lrs = [1e-4, 1e-5, 2e-5]\n",
    "num_epochs = 35\n",
    "num_classes = 5\n",
    "\n",
    "\n",
    "def run_experiment(batch_size, lr):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = MaiaNet(num_classes)\n",
    "    trainer = Trainer(model, train_loader, val_loader, test_loader, lr, num_epochs, batch_size=batch_size)\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650ee9fc-d639-472f-879b-d6b3e1d17449",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running experiment with batch_size=32, lr=0.0001\n",
      "\n",
      "Running experiment with batch_size=32, lr=1e-05\n",
      "\n",
      "Running experiment with batch_size=32, lr=2e-05\n",
      "\n",
      "Running experiment with batch_size=16, lr=0.0001\n",
      "\n",
      "Running experiment with batch_size=16, lr=1e-05\n",
      "\n",
      "Running experiment with batch_size=16, lr=2e-05\n",
      "\n",
      "Running experiment with batch_size=12, lr=0.0001\n",
      "\n",
      "Running experiment with batch_size=12, lr=1e-05\n",
      "\n",
      "Running experiment with batch_size=12, lr=2e-05\n",
      "\n",
      "Running experiment with batch_size=8, lr=0.0001\n",
      "\n",
      "Running experiment with batch_size=8, lr=1e-05\n",
      "\n",
      "Running experiment with batch_size=8, lr=2e-05\n",
      "\n",
      "Running experiment with batch_size=4, lr=0.0001\n",
      "\n",
      "Running experiment with batch_size=4, lr=1e-05\n",
      "\n",
      "Running experiment with batch_size=4, lr=2e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/35: 100%|██████████| 126/126 [05:26<00:00,  2.59s/it, loss=1.5914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 0\n",
      "Train Loss: 1.6117\n",
      "Test Loss: 1.6072\n",
      "Accuracy: 0.2143\n",
      "Precision: 0.1145\n",
      "Recall: 0.2143\n",
      "F1: 0.0989\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/35: 100%|██████████| 126/126 [05:17<00:00,  2.52s/it, loss=1.5751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Running experiment with batch_size=16, lr=0.0001\n",
      "Epoch: 1\n",
      "Train Loss: 1.6061\n",
      "Test Loss: 1.6065\n",
      "Accuracy: 0.2024\n",
      "Precision: 0.0410\n",
      "Recall: 0.2024\n",
      "F1: 0.0681\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/35: 100%|██████████| 126/126 [05:15<00:00,  2.50s/it, loss=1.5901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 2\n",
      "Train Loss: 1.6039\n",
      "Test Loss: 1.6001\n",
      "Accuracy: 0.2817\n",
      "Precision: 0.1540\n",
      "Recall: 0.2817\n",
      "F1: 0.1773\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/35: 100%|██████████| 126/126 [05:19<00:00,  2.54s/it, loss=1.5883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 3\n",
      "Train Loss: 1.6000\n",
      "Test Loss: 1.5995\n",
      "Accuracy: 0.2659\n",
      "Precision: 0.1663\n",
      "Recall: 0.2659\n",
      "F1: 0.1912\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/35: 100%|██████████| 126/126 [05:13<00:00,  2.49s/it, loss=1.6275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 4\n",
      "Train Loss: 1.5957\n",
      "Test Loss: 1.5931\n",
      "Accuracy: 0.2698\n",
      "Precision: 0.2012\n",
      "Recall: 0.2698\n",
      "F1: 0.1896\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/35: 100%|██████████| 126/126 [05:15<00:00,  2.50s/it, loss=1.5633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 5\n",
      "Train Loss: 1.5907\n",
      "Test Loss: 1.5902\n",
      "Accuracy: 0.2659\n",
      "Precision: 0.1250\n",
      "Recall: 0.2659\n",
      "F1: 0.1529\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/35: 100%|██████████| 126/126 [05:22<00:00,  2.56s/it, loss=1.6039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 6\n",
      "Train Loss: 1.5866\n",
      "Test Loss: 1.5882\n",
      "Accuracy: 0.2421\n",
      "Precision: 0.1107\n",
      "Recall: 0.2421\n",
      "F1: 0.1228\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/35: 100%|██████████| 126/126 [05:08<00:00,  2.45s/it, loss=1.5677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 7\n",
      "Train Loss: 1.5799\n",
      "Test Loss: 1.5850\n",
      "Accuracy: 0.3175\n",
      "Precision: 0.2859\n",
      "Recall: 0.3175\n",
      "F1: 0.2274\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/35: 100%|██████████| 126/126 [05:27<00:00,  2.60s/it, loss=1.5877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 8\n",
      "Train Loss: 1.5749\n",
      "Test Loss: 1.5801\n",
      "Accuracy: 0.3056\n",
      "Precision: 0.2805\n",
      "Recall: 0.3056\n",
      "F1: 0.2386\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/35: 100%|██████████| 126/126 [05:16<00:00,  2.51s/it, loss=1.5941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 9\n",
      "Train Loss: 1.5702\n",
      "Test Loss: 1.5776\n",
      "Accuracy: 0.2778\n",
      "Precision: 0.2210\n",
      "Recall: 0.2778\n",
      "F1: 0.1767\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/35: 100%|██████████| 126/126 [05:14<00:00,  2.49s/it, loss=1.5377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 10\n",
      "Train Loss: 1.5673\n",
      "Test Loss: 1.5725\n",
      "Accuracy: 0.3611\n",
      "Precision: 0.5608\n",
      "Recall: 0.3611\n",
      "F1: 0.3101\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/35: 100%|██████████| 126/126 [05:14<00:00,  2.49s/it, loss=1.5574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 11\n",
      "Train Loss: 1.5607\n",
      "Test Loss: 1.5678\n",
      "Accuracy: 0.3214\n",
      "Precision: 0.3967\n",
      "Recall: 0.3214\n",
      "F1: 0.2831\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/35: 100%|██████████| 126/126 [05:13<00:00,  2.49s/it, loss=1.5500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 12\n",
      "Train Loss: 1.5561\n",
      "Test Loss: 1.5641\n",
      "Accuracy: 0.3056\n",
      "Precision: 0.3887\n",
      "Recall: 0.3056\n",
      "F1: 0.2617\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/35: 100%|██████████| 126/126 [05:15<00:00,  2.50s/it, loss=1.5810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 13\n",
      "Train Loss: 1.5510\n",
      "Test Loss: 1.5624\n",
      "Accuracy: 0.3571\n",
      "Precision: 0.5094\n",
      "Recall: 0.3571\n",
      "F1: 0.3084\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/35:  83%|████████▎ | 105/126 [04:21<00:49,  2.37s/it, loss=1.5309]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 14\n",
      "Train Loss: 1.5467\n",
      "Test Loss: 1.5566\n",
      "Accuracy: 0.3690\n",
      "Precision: 0.3776\n",
      "Recall: 0.3690\n",
      "F1: 0.3529\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/35: 100%|██████████| 126/126 [05:18<00:00,  2.53s/it, loss=1.5444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 15\n",
      "Train Loss: 1.5417\n",
      "Test Loss: 1.5554\n",
      "Accuracy: 0.3175\n",
      "Precision: 0.4628\n",
      "Recall: 0.3175\n",
      "F1: 0.2850\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/35: 100%|██████████| 126/126 [05:19<00:00,  2.54s/it, loss=1.5374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 16\n",
      "Train Loss: 1.5376\n",
      "Test Loss: 1.5499\n",
      "Accuracy: 0.3095\n",
      "Precision: 0.2946\n",
      "Recall: 0.3095\n",
      "F1: 0.2525\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/35: 100%|██████████| 126/126 [05:13<00:00,  2.49s/it, loss=1.5299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 17\n",
      "Train Loss: 1.5326\n",
      "Test Loss: 1.5440\n",
      "Accuracy: 0.3492\n",
      "Precision: 0.4130\n",
      "Recall: 0.3492\n",
      "F1: 0.2975\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/35: 100%|██████████| 126/126 [06:40<00:00,  3.18s/it, loss=1.5336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 18\n",
      "Train Loss: 1.5276\n",
      "Test Loss: 1.5431\n",
      "Accuracy: 0.4127\n",
      "Precision: 0.4166\n",
      "Recall: 0.4127\n",
      "F1: 0.3917\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/35: 100%|██████████| 126/126 [05:46<00:00,  2.75s/it, loss=1.5278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 19\n",
      "Train Loss: 1.5247\n",
      "Test Loss: 1.5419\n",
      "Accuracy: 0.3333\n",
      "Precision: 0.4717\n",
      "Recall: 0.3333\n",
      "F1: 0.2962\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/35: 100%|██████████| 126/126 [05:49<00:00,  2.77s/it, loss=1.4796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 20\n",
      "Train Loss: 1.5192\n",
      "Test Loss: 1.5401\n",
      "Accuracy: 0.3492\n",
      "Precision: 0.3810\n",
      "Recall: 0.3492\n",
      "F1: 0.3200\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/35: 100%|██████████| 126/126 [05:47<00:00,  2.76s/it, loss=1.4907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Metrics:\n",
      "--------------------------------------------------\n",
      "Epoch: 21\n",
      "Train Loss: 1.5159\n",
      "Test Loss: 1.5351\n",
      "Accuracy: 0.3611\n",
      "Precision: 0.4847\n",
      "Recall: 0.3611\n",
      "F1: 0.3461\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/35:   6%|▋         | 8/126 [00:22<04:58,  2.53s/it, loss=1.4846]"
     ]
    }
   ],
   "source": [
    "# for batch_size, lr in itertools.product(batch_sizes, lrs):\n",
    "#     print(f\"\\nRunning experiment with batch_size={batch_size}, lr={lr}\")\n",
    "\n",
    "batch_size = 16\n",
    "lr = 1e-4\n",
    "run_experiment(batch_size, lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

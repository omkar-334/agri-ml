{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ea79405-3e58-4040-9d4b-79697654f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch pandas torchvision scikit-learn tqdm kaggle -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d482ea-0e22-4b07-a205-1d259fb90a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b990dab2-2199-4cc7-b547-bd3ad9a34014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading cassava-leaf-disease-classification.zip to /home/ubuntu\n",
      "100%|██████████████████████████████████████▉| 5.76G/5.76G [00:40<00:00, 230MB/s]\n",
      "100%|███████████████████████████████████████| 5.76G/5.76G [00:40<00:00, 153MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c cassava-leaf-disease-classification\n",
    "!unzip -q cassava-leaf-disease-classification.zip -d cassava_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1282e13-654a-4974-b4b9-3cf848b99bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    13158\n",
      "4     2577\n",
      "2     2386\n",
      "1     2189\n",
      "0     1087\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((448, 448)),  # Resize to input size of MaiaNet\n",
    "        transforms.RandomHorizontalFlip(p=0.5),  # Horizontal flipping\n",
    "        transforms.RandomVerticalFlip(p=0.5),  # Vertical flipping\n",
    "        transforms.ToTensor(),  # Convert to tensor before adding noise\n",
    "        transforms.Lambda(lambda x: x + torch.randn_like(x) * 0.05),  # Add Gaussian noise\n",
    "        transforms.Lambda(lambda x: transforms.functional.erase(x, i=0, j=0, h=50, w=50, v=0.0)),  # Add cutout\n",
    "    ]\n",
    ")\n",
    "\n",
    "# df = pd.read_csv(\"train.csv\")\n",
    "df = pd.read_csv(\"cassava_data/train.csv\")\n",
    "\n",
    "print(df.label.value_counts())\n",
    "balanced_df = pd.DataFrame()\n",
    "\n",
    "for label in df[\"label\"].unique():\n",
    "    label_df = df[df[\"label\"] == label]\n",
    "    if len(label_df) > 1000:\n",
    "        _, sampled_df = train_test_split(label_df, test_size=500, random_state=42, stratify=label_df[\"label\"])\n",
    "    balanced_df = pd.concat([balanced_df, sampled_df])\n",
    "\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = \"cassava_data/train_images\"\n",
    "        self.transform = transform\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.dataframe.iloc[idx][\"image_id\"]\n",
    "        label = self.dataframe.iloc[idx][\"label\"]\n",
    "        image_path = os.path.join(self.image_dir, image_id)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        # Move tensors to GPU if available\n",
    "        image = image.to(device)\n",
    "        label = torch.tensor(label, device=device)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2ba8c31-2cf8-4315-a109-bb206a542f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(balanced_df, test_size=0.3, random_state=42, stratify=balanced_df[\"label\"])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"label\"])\n",
    "\n",
    "train_dataset = Dataset(train_df)\n",
    "test_dataset = Dataset(test_df)\n",
    "val_dataset = Dataset(val_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f478e778-23ed-44bd-a407-09d837e63d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import ResNet\n",
    "\n",
    "\n",
    "def get_freq_indices(method):\n",
    "    assert method in [\"top1\", \"top2\", \"top4\", \"top8\", \"top16\", \"top32\", \"bot1\", \"bot2\", \"bot4\", \"bot8\", \"bot16\", \"bot32\", \"low1\", \"low2\", \"low4\", \"low8\", \"low16\", \"low32\"]\n",
    "    num_freq = int(method[3:])\n",
    "    if \"top\" in method:\n",
    "        all_top_indices_x = [0, 0, 6, 0, 0, 1, 1, 4, 5, 1, 3, 0, 0, 0, 3, 2, 4, 6, 3, 5, 5, 2, 6, 5, 5, 3, 3, 4, 2, 2, 6, 1]\n",
    "        all_top_indices_y = [0, 1, 0, 5, 2, 0, 2, 0, 0, 6, 0, 4, 6, 3, 5, 2, 6, 3, 3, 3, 5, 1, 1, 2, 4, 2, 1, 1, 3, 0, 5, 3]\n",
    "        mapper_x = all_top_indices_x[:num_freq]\n",
    "        mapper_y = all_top_indices_y[:num_freq]\n",
    "    elif \"low\" in method:\n",
    "        all_low_indices_x = [0, 0, 1, 1, 0, 2, 2, 1, 2, 0, 3, 4, 0, 1, 3, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4]\n",
    "        all_low_indices_y = [0, 1, 0, 1, 2, 0, 1, 2, 2, 3, 0, 0, 4, 3, 1, 5, 4, 3, 2, 1, 0, 6, 5, 4, 3, 2, 1, 0, 6, 5, 4, 3]\n",
    "        mapper_x = all_low_indices_x[:num_freq]\n",
    "        mapper_y = all_low_indices_y[:num_freq]\n",
    "    elif \"bot\" in method:\n",
    "        all_bot_indices_x = [6, 1, 3, 3, 2, 4, 1, 2, 4, 4, 5, 1, 4, 6, 2, 5, 6, 1, 6, 2, 2, 4, 3, 3, 5, 5, 6, 2, 5, 5, 3, 6]\n",
    "        all_bot_indices_y = [6, 4, 4, 6, 6, 3, 1, 4, 4, 5, 6, 5, 2, 2, 5, 1, 4, 3, 5, 0, 3, 1, 1, 2, 4, 2, 1, 1, 5, 3, 3, 3]\n",
    "        mapper_x = all_bot_indices_x[:num_freq]\n",
    "        mapper_y = all_bot_indices_y[:num_freq]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return mapper_x, mapper_y\n",
    "\n",
    "\n",
    "class MultiSpectralAttentionLayer(torch.nn.Module):\n",
    "    def __init__(self, channel, dct_h, dct_w, reduction=16, freq_sel_method=\"top16\"):\n",
    "        super(MultiSpectralAttentionLayer, self).__init__()\n",
    "        self.reduction = reduction\n",
    "        self.dct_h = dct_h\n",
    "        self.dct_w = dct_w\n",
    "\n",
    "        mapper_x, mapper_y = get_freq_indices(freq_sel_method)\n",
    "        self.num_split = len(mapper_x)\n",
    "        mapper_x = [temp_x * (dct_h // 7) for temp_x in mapper_x]\n",
    "        mapper_y = [temp_y * (dct_w // 7) for temp_y in mapper_y]\n",
    "        # make the frequencies in different sizes are identical to a 7x7 frequency space\n",
    "        # eg, (2,2) in 14x14 is identical to (1,1) in 7x7\n",
    "\n",
    "        self.dct_layer = MultiSpectralDCTLayer(dct_h, dct_w, mapper_x, mapper_y, channel)\n",
    "        self.fc = nn.Sequential(nn.Linear(channel, channel // reduction, bias=False), nn.ReLU(), nn.Linear(channel // reduction, channel, bias=False), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        n, c, h, w = x.shape\n",
    "        x_pooled = x\n",
    "        if h != self.dct_h or w != self.dct_w:\n",
    "            x_pooled = torch.nn.functional.adaptive_avg_pool2d(x, (self.dct_h, self.dct_w))\n",
    "            # If you have concerns about one-line-change, don't worry.   :)\n",
    "            # In the ImageNet models, this line will never be triggered.\n",
    "            # This is for compatibility in instance segmentation and object detection.\n",
    "        y = self.dct_layer(x_pooled)\n",
    "\n",
    "        y = self.fc(y).view(n, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class MultiSpectralDCTLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Generate dct filters\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, height, width, mapper_x, mapper_y, channel):\n",
    "        super(MultiSpectralDCTLayer, self).__init__()\n",
    "\n",
    "        assert len(mapper_x) == len(mapper_y)\n",
    "        assert channel % len(mapper_x) == 0\n",
    "\n",
    "        self.num_freq = len(mapper_x)\n",
    "\n",
    "        # fixed DCT init\n",
    "        self.register_buffer(\"weight\", self.get_dct_filter(height, width, mapper_x, mapper_y, channel))\n",
    "\n",
    "        # fixed random init\n",
    "        # self.register_buffer('weight', torch.rand(channel, height, width))\n",
    "\n",
    "        # learnable DCT init\n",
    "        # self.register_parameter('weight', self.get_dct_filter(height, width, mapper_x, mapper_y, channel))\n",
    "\n",
    "        # learnable random init\n",
    "        # self.register_parameter('weight', torch.rand(channel, height, width))\n",
    "\n",
    "        # num_freq, h, w\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 4, \"x must been 4 dimensions, but got \" + str(len(x.shape))\n",
    "        # n, c, h, w = x.shape\n",
    "\n",
    "        x = x * self.weight\n",
    "\n",
    "        result = torch.sum(x, dim=[2, 3])\n",
    "        return result\n",
    "\n",
    "    def build_filter(self, pos, freq, POS):\n",
    "        result = math.cos(math.pi * freq * (pos + 0.5) / POS) / math.sqrt(POS)\n",
    "        if freq == 0:\n",
    "            return result\n",
    "        else:\n",
    "            return result * math.sqrt(2)\n",
    "\n",
    "    def get_dct_filter(self, tile_size_x, tile_size_y, mapper_x, mapper_y, channel):\n",
    "        dct_filter = torch.zeros(channel, tile_size_x, tile_size_y)\n",
    "\n",
    "        c_part = channel // len(mapper_x)\n",
    "\n",
    "        for i, (u_x, v_y) in enumerate(zip(mapper_x, mapper_y)):\n",
    "            for t_x in range(tile_size_x):\n",
    "                for t_y in range(tile_size_y):\n",
    "                    dct_filter[i * c_part : (i + 1) * c_part, t_x, t_y] = self.build_filter(t_x, u_x, tile_size_x) * self.build_filter(t_y, v_y, tile_size_y)\n",
    "\n",
    "        return dct_filter\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "    \n",
    "import torch.nn as nn\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torchvision.models import ResNet\n",
    "\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(nn.Linear(channel, channel // reduction, bias=False), nn.ReLU(), nn.Linear(channel // reduction, channel, bias=False), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class MaiaNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MaiaNet, self).__init__()\n",
    "        self.head = HeadBlock(3, 64)  # Input: 448×448×3 -> 112×112×64\n",
    "        self.anti_aliasing_1 = AntiAliasingBlock(64, 64, downsample=False)  # 112×112×64 -> 112×112×64\n",
    "        self.maia_1 = MaiaBlock(64, 256)  # 112×112×64 -> 112×112×256\n",
    "        self.anti_aliasing_2 = AntiAliasingBlock(256, 512, downsample=True)  # 112×112×256 -> 56×56×512\n",
    "        self.maia_2 = MaiaBlock(512, 512)  # 56×56×512 -> 56×56×512\n",
    "        self.anti_aliasing_3 = AntiAliasingBlock(512, 1024, downsample=True)  # 56×56×512 -> 28×28×1024\n",
    "        self.maia_3 = MaiaBlock(1024, 1024)  # 28×28×1024 -> 28×28×1024\n",
    "        self.maia_4 = MaiaBlock(1024, 2048, downsample=True)  # 14×14×2048 -> 14×14×2048\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))  # Converts 14x14x2048 to 1x1x2048\n",
    "        self.fc = nn.Linear(2048, num_classes)  # Fully connected layer (2048 -> num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        if verbose:\n",
    "            print(\"Input:\", x.shape)\n",
    "        x = self.head(x)\n",
    "        if verbose:\n",
    "            print(\"Head:\", x.shape)\n",
    "        x = self.anti_aliasing_1(x)\n",
    "        if verbose:\n",
    "            print(\"Anti-aliasing 1:\", x.shape)\n",
    "        x = self.maia_1(x)\n",
    "        if verbose:\n",
    "            print(\"MAIA 1:\", x.shape)\n",
    "        x = self.anti_aliasing_2(x)\n",
    "        if verbose:\n",
    "            print(\"Anti-aliasing 2:\", x.shape)\n",
    "        x = self.maia_2(x)\n",
    "        if verbose:\n",
    "            print(\"MAIA 2:\", x.shape)\n",
    "        x = self.anti_aliasing_3(x)\n",
    "        if verbose:\n",
    "            print(\"Anti-aliasing 3:\", x.shape)\n",
    "        x = self.maia_3(x)\n",
    "        if verbose:\n",
    "            print(\"MAIA 3:\", x.shape)\n",
    "        x = self.maia_4(x)\n",
    "        if verbose:\n",
    "            print(\"MAIA 4:\", x.shape)\n",
    "\n",
    "        x = self.global_pool(x)  # Shape: (batch_size, 2048, 1, 1)\n",
    "        x = torch.flatten(x, 1)  # Shape: (batch_size, 2048)\n",
    "        x = self.fc(x)  # Shape: (batch_size, num_classes)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class HeadBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(HeadBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=7, padding=3, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(MultiAttention, self).__init__()\n",
    "\n",
    "        # https://github.com/hujie-frank/SENet/blob/master/README.md\n",
    "        self.se = SELayer(in_channels, reduction=16)\n",
    "\n",
    "        # https://github.com/cfzd/FcaNet/blob/master/model/fcanet.py\n",
    "        self.fca = MultiSpectralAttentionLayer(in_channels, 7, 7, reduction=16, freq_sel_method=\"top16\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.se(x)\n",
    "        x = self.fca(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AntiAliasingBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample=True):\n",
    "        super(AntiAliasingBlock, self).__init__()\n",
    "\n",
    "        self.downsample = downsample\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.down_conversion = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, groups=out_channels),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        stride = 2 if self.downsample else 1\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "        self.ma = MultiAttention(out_channels)\n",
    "        self.ibn = nn.InstanceNorm2d(out_channels)\n",
    "\n",
    "        self.residual_conv = None\n",
    "        if in_channels != out_channels or downsample:\n",
    "            self.residual_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.residual_conv = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block1(x)\n",
    "        out = self.down_conversion(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.ma(out)\n",
    "        if self.residual_conv:\n",
    "            x = self.residual_conv(x)\n",
    "        out = out + x\n",
    "        out = self.ibn(out)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MaiaBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample=False):\n",
    "        super(MaiaBlock, self).__init__()\n",
    "\n",
    "        stride = 2 if downsample else 1\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.ma = MultiAttention(out_channels)\n",
    "        self.ibn = nn.InstanceNorm2d(out_channels)\n",
    "\n",
    "        if in_channels != out_channels or downsample:\n",
    "            self.residual_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.residual_conv = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.ma(out)\n",
    "\n",
    "        if self.residual_conv:\n",
    "            x = self.residual_conv(x)\n",
    "        out = out + x\n",
    "        out = self.ibn(out)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = MaiaNet(num_classes=5).to(device)\n",
    "    x = torch.randn(1, 3, 448, 448).to(device)\n",
    "    output = model(x)\n",
    "    print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef7d3c56-894d-4027-97e0-4886a0320c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.cuda.amp as amp  # For mixed precision training\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from tqdm import tqdm\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, test_loader, lr=0.2, num_epochs=80):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = model.to(self.device)\n",
    "\n",
    "        # Enable cudnn benchmarking for better performance\n",
    "        if torch.cuda.is_available():\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.num_epochs = num_epochs\n",
    "        self.lr = lr\n",
    "\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=self.lr, momentum=0.9, weight_decay=1e-5)\n",
    "        self.scheduler = ExponentialLR(self.optimizer, gamma=0.96)\n",
    "        self.criterion = nn.CrossEntropyLoss().to(self.device)  # Move loss function to GPU\n",
    "\n",
    "        # Initialize mixed precision training\n",
    "        self.scaler = torch.amp.GradScaler()\n",
    "\n",
    "        self.best_val_loss = float(\"inf\")\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        pbar = tqdm(self.train_loader, desc=f\"Epoch {epoch + 1}/{self.num_epochs}\")\n",
    "\n",
    "        for images, labels in pbar:\n",
    "            # Clear GPU cache if needed\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            images = images.to(self.device, non_blocking=True)\n",
    "            labels = labels.to(self.device, non_blocking=True)\n",
    "\n",
    "            self.optimizer.zero_grad(set_to_none=True)  # More efficient than zero_grad()\n",
    "\n",
    "            # Use mixed precision training\n",
    "            with amp.autocast():\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "            # Scale the loss and perform backprop\n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "\n",
    "            # self.scaler.step(self.optimizer)\n",
    "            # self.scaler.update()\n",
    "            # self.optimizer.zero_grad(set_to_none=True)  # AFTER scaler update\n",
    "\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "            # Delete unnecessary tensors\n",
    "            del outputs, loss\n",
    "\n",
    "        self.scheduler.step()\n",
    "\n",
    "        return total_loss / len(self.train_loader)\n",
    "\n",
    "    @torch.no_grad()  # More efficient than with torch.no_grad()\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        for images, labels in self.val_loader:\n",
    "            images = images.to(self.device, non_blocking=True)\n",
    "            labels = labels.to(self.device, non_blocking=True)\n",
    "\n",
    "            with amp.autocast():\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Clean up GPU memory\n",
    "            del outputs, loss\n",
    "\n",
    "        avg_loss = total_loss / len(self.val_loader.dataset)\n",
    "        metrics = self.calculate_metrics(all_preds, all_labels)\n",
    "\n",
    "        return avg_loss, metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_metrics(predictions, labels):\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\", zero_division=0)\n",
    "        return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "    @staticmethod\n",
    "    def print_metrics(metrics, phase):\n",
    "        print(f\"\\n{phase} Metrics:\")\n",
    "        print(\"-\" * 50)\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    def train(self):\n",
    "        try:\n",
    "            for epoch in range(self.num_epochs):\n",
    "                train_loss = self.train_epoch(epoch)\n",
    "                val_loss, val_metrics = self.validate()\n",
    "\n",
    "                print(f\"\\nEpoch {epoch + 1}: Train Loss = {train_loss:.4f} | Val Loss = {val_loss:.4f}\")\n",
    "                self.print_metrics(val_metrics, \"Validation\")\n",
    "\n",
    "                if val_loss < self.best_val_loss:\n",
    "                    self.best_val_loss = val_loss\n",
    "                    # Save model state to CPU to avoid GPU memory issues\n",
    "                    self.best_model_state = {k: v.cpu() for k, v in self.model.state_dict().items()}\n",
    "\n",
    "                # Print GPU memory usage if available\n",
    "                if torch.cuda.is_available():\n",
    "                    print(f\"GPU Memory allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Training interrupted: {str(e)}\")\n",
    "            # Save the current best model if training is interrupted\n",
    "            if self.best_model_state is not None:\n",
    "                torch.save(self.best_model_state, \"interrupted_model.pt\")\n",
    "\n",
    "    def test(self):\n",
    "        # Load best model state back to GPU\n",
    "        if self.best_model_state is not None:\n",
    "            self.model.load_state_dict({k: v.to(self.device) for k, v in self.best_model_state.items()})\n",
    "        test_loss, test_metrics = self.validate()\n",
    "        print(\"\\nBest Model Performance on Test Set:\")\n",
    "        self.print_metrics(test_metrics, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4477227e-0b6d-4593-bbc3-da028ad14f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, train_loader, test_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a9b82e-c7f5-4a31-9205-9f4e361e7dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1786/4096524110.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Epoch 1/80: 100%|██████████| 55/55 [01:20<00:00,  1.46s/it, loss=1.7581]\n",
      "/tmp/ipykernel_1786/4096524110.py:82: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: Train Loss = 1.6987 | Val Loss = 1.7156\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.1973\n",
      "Precision: 0.0398\n",
      "Recall: 0.1973\n",
      "F1: 0.0662\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 3.33 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/80: 100%|██████████| 55/55 [01:04<00:00,  1.18s/it, loss=1.8591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: Train Loss = 1.7220 | Val Loss = 1.6886\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.2000\n",
      "Precision: 0.0401\n",
      "Recall: 0.2000\n",
      "F1: 0.0668\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 3.33 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/80: 100%|██████████| 55/55 [01:05<00:00,  1.20s/it, loss=1.6848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: Train Loss = 1.7365 | Val Loss = 1.6862\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.2000\n",
      "Precision: 0.0400\n",
      "Recall: 0.2000\n",
      "F1: 0.0667\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 3.34 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/80: 100%|██████████| 55/55 [01:04<00:00,  1.18s/it, loss=1.5468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: Train Loss = 1.6846 | Val Loss = 1.6989\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.2053\n",
      "Precision: 0.0903\n",
      "Recall: 0.2053\n",
      "F1: 0.0935\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 3.33 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/80: 100%|██████████| 55/55 [01:04<00:00,  1.17s/it, loss=1.6163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: Train Loss = 1.7206 | Val Loss = 1.7412\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.1920\n",
      "Precision: 0.0674\n",
      "Recall: 0.1920\n",
      "F1: 0.0732\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 3.33 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/80: 100%|██████████| 55/55 [01:06<00:00,  1.20s/it, loss=1.5530]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: Train Loss = 1.6458 | Val Loss = 1.6433\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.2000\n",
      "Precision: 0.0400\n",
      "Recall: 0.2000\n",
      "F1: 0.0667\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/80: 100%|██████████| 55/55 [01:05<00:00,  1.19s/it, loss=1.5949]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: Train Loss = 1.6344 | Val Loss = 1.6108\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.2587\n",
      "Precision: 0.1046\n",
      "Recall: 0.2587\n",
      "F1: 0.1488\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/80: 100%|██████████| 55/55 [01:03<00:00,  1.16s/it, loss=1.4596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: Train Loss = 1.6243 | Val Loss = 1.6247\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.2133\n",
      "Precision: 0.1521\n",
      "Recall: 0.2133\n",
      "F1: 0.0918\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/80: 100%|██████████| 55/55 [01:05<00:00,  1.20s/it, loss=1.7267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: Train Loss = 1.6608 | Val Loss = 1.7685\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.2693\n",
      "Precision: 0.1879\n",
      "Recall: 0.2693\n",
      "F1: 0.1842\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/80: 100%|██████████| 55/55 [01:04<00:00,  1.18s/it, loss=1.5570]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: Train Loss = 1.6043 | Val Loss = 1.5961\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.2480\n",
      "Precision: 0.1019\n",
      "Recall: 0.2480\n",
      "F1: 0.1341\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/80: 100%|██████████| 55/55 [01:05<00:00,  1.19s/it, loss=1.3557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: Train Loss = 1.5197 | Val Loss = 1.4784\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3173\n",
      "Precision: 0.2788\n",
      "Recall: 0.3173\n",
      "F1: 0.2569\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/80: 100%|██████████| 55/55 [01:03<00:00,  1.16s/it, loss=1.5795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: Train Loss = 1.5279 | Val Loss = 1.4769\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3440\n",
      "Precision: 0.2942\n",
      "Recall: 0.3440\n",
      "F1: 0.2800\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/80: 100%|██████████| 55/55 [01:04<00:00,  1.18s/it, loss=1.6293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: Train Loss = 1.5148 | Val Loss = 1.4809\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3307\n",
      "Precision: 0.1996\n",
      "Recall: 0.3307\n",
      "F1: 0.2454\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/80: 100%|██████████| 55/55 [01:06<00:00,  1.21s/it, loss=1.6723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: Train Loss = 1.4846 | Val Loss = 1.4195\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3840\n",
      "Precision: 0.3473\n",
      "Recall: 0.3840\n",
      "F1: 0.3297\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/80: 100%|██████████| 55/55 [01:05<00:00,  1.19s/it, loss=1.5649]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: Train Loss = 1.4905 | Val Loss = 1.4278\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3040\n",
      "Precision: 0.2776\n",
      "Recall: 0.3040\n",
      "F1: 0.2349\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/80: 100%|██████████| 55/55 [01:06<00:00,  1.20s/it, loss=1.2466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: Train Loss = 1.4915 | Val Loss = 1.5051\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.2880\n",
      "Precision: 0.1328\n",
      "Recall: 0.2880\n",
      "F1: 0.1728\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/80: 100%|██████████| 55/55 [01:06<00:00,  1.21s/it, loss=2.2739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17: Train Loss = 1.4793 | Val Loss = 1.6928\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3227\n",
      "Precision: 0.2734\n",
      "Recall: 0.3227\n",
      "F1: 0.2775\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/80: 100%|██████████| 55/55 [01:06<00:00,  1.21s/it, loss=1.7020]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: Train Loss = 1.4444 | Val Loss = 1.3967\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3440\n",
      "Precision: 0.3038\n",
      "Recall: 0.3440\n",
      "F1: 0.3041\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/80: 100%|██████████| 55/55 [01:07<00:00,  1.22s/it, loss=1.8199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: Train Loss = 1.4073 | Val Loss = 1.3968\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3493\n",
      "Precision: 0.2671\n",
      "Recall: 0.3493\n",
      "F1: 0.2384\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/80: 100%|██████████| 55/55 [01:05<00:00,  1.19s/it, loss=1.4526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: Train Loss = 1.4519 | Val Loss = 1.4356\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3067\n",
      "Precision: 0.2091\n",
      "Recall: 0.3067\n",
      "F1: 0.1876\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/80: 100%|██████████| 55/55 [01:05<00:00,  1.19s/it, loss=1.5042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21: Train Loss = 1.4965 | Val Loss = 1.4765\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.2987\n",
      "Precision: 0.1206\n",
      "Recall: 0.2987\n",
      "F1: 0.1705\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/80: 100%|██████████| 55/55 [01:05<00:00,  1.19s/it, loss=1.2725]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: Train Loss = 1.4110 | Val Loss = 1.3884\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3680\n",
      "Precision: 0.3052\n",
      "Recall: 0.3680\n",
      "F1: 0.2957\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/80: 100%|██████████| 55/55 [01:04<00:00,  1.17s/it, loss=1.4003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23: Train Loss = 1.4123 | Val Loss = 1.4258\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3813\n",
      "Precision: 0.3493\n",
      "Recall: 0.3813\n",
      "F1: 0.3362\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/80: 100%|██████████| 55/55 [01:06<00:00,  1.21s/it, loss=1.4085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24: Train Loss = 1.3982 | Val Loss = 1.4233\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3467\n",
      "Precision: 0.2527\n",
      "Recall: 0.3467\n",
      "F1: 0.2460\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/80: 100%|██████████| 55/55 [01:05<00:00,  1.20s/it, loss=1.2086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25: Train Loss = 1.3510 | Val Loss = 1.4692\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3200\n",
      "Precision: 0.1883\n",
      "Recall: 0.3200\n",
      "F1: 0.2210\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/80: 100%|██████████| 55/55 [01:04<00:00,  1.18s/it, loss=1.3179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: Train Loss = 1.3852 | Val Loss = 1.3559\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3547\n",
      "Precision: 0.2724\n",
      "Recall: 0.3547\n",
      "F1: 0.2852\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/80: 100%|██████████| 55/55 [01:04<00:00,  1.17s/it, loss=1.3419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27: Train Loss = 1.3497 | Val Loss = 1.3765\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3333\n",
      "Precision: 0.3372\n",
      "Recall: 0.3333\n",
      "F1: 0.3043\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/80: 100%|██████████| 55/55 [01:06<00:00,  1.20s/it, loss=1.1307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28: Train Loss = 1.3626 | Val Loss = 1.5488\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.2907\n",
      "Precision: 0.1649\n",
      "Recall: 0.2907\n",
      "F1: 0.2042\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/80: 100%|██████████| 55/55 [01:06<00:00,  1.21s/it, loss=1.1593]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29: Train Loss = 1.3813 | Val Loss = 1.4299\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3680\n",
      "Precision: 0.2515\n",
      "Recall: 0.3680\n",
      "F1: 0.2863\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/80: 100%|██████████| 55/55 [01:04<00:00,  1.17s/it, loss=1.1704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: Train Loss = 1.3156 | Val Loss = 1.4027\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3600\n",
      "Precision: 0.3602\n",
      "Recall: 0.3600\n",
      "F1: 0.2728\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/80: 100%|██████████| 55/55 [01:04<00:00,  1.16s/it, loss=1.2982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31: Train Loss = 1.3040 | Val Loss = 1.5456\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3573\n",
      "Precision: 0.3204\n",
      "Recall: 0.3573\n",
      "F1: 0.2989\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/80: 100%|██████████| 55/55 [01:03<00:00,  1.16s/it, loss=1.5399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32: Train Loss = 1.3389 | Val Loss = 1.3948\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3920\n",
      "Precision: 0.4039\n",
      "Recall: 0.3920\n",
      "F1: 0.3669\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/80: 100%|██████████| 55/55 [01:03<00:00,  1.16s/it, loss=1.3319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33: Train Loss = 1.3065 | Val Loss = 1.4220\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3787\n",
      "Precision: 0.3430\n",
      "Recall: 0.3787\n",
      "F1: 0.3148\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/80: 100%|██████████| 55/55 [01:04<00:00,  1.17s/it, loss=1.4498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34: Train Loss = 1.2666 | Val Loss = 1.3620\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.4133\n",
      "Precision: 0.4583\n",
      "Recall: 0.4133\n",
      "F1: 0.3868\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/80: 100%|██████████| 55/55 [01:06<00:00,  1.21s/it, loss=1.1704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35: Train Loss = 1.2828 | Val Loss = 1.3636\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.4133\n",
      "Precision: 0.3436\n",
      "Recall: 0.4133\n",
      "F1: 0.3552\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/80: 100%|██████████| 55/55 [01:06<00:00,  1.20s/it, loss=1.2495]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36: Train Loss = 1.2689 | Val Loss = 1.4111\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3520\n",
      "Precision: 0.2773\n",
      "Recall: 0.3520\n",
      "F1: 0.2368\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/80: 100%|██████████| 55/55 [01:04<00:00,  1.16s/it, loss=1.2728]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37: Train Loss = 1.2765 | Val Loss = 1.3991\n",
      "\n",
      "Validation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.4107\n",
      "Precision: 0.3946\n",
      "Recall: 0.4107\n",
      "F1: 0.3940\n",
      "--------------------------------------------------\n",
      "GPU Memory allocated: 2.62 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/80:  44%|████▎     | 24/55 [00:28<00:36,  1.17s/it, loss=1.2203]"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "455c151f-5029-41a5-a15e-356ed1ab6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d2b5f66-e34d-4981-8598-7463d7fd6fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1786/4096524110.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Epoch 2/80: 100%|██████████| 55/55 [01:03<00:00,  1.16s/it, loss=0.4588]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6500176305120642"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train_epoch(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch numpy pandas torchvision scikit-learn tqdm kaggle -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload kaggle.json first.\n",
    "!mkdir -p ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt update -qq\n",
    "!apt install -qq unzip\n",
    "!kaggle datasets download nirmalsankalana/sugarcane-leaf-disease-dataset\n",
    "!unzip -q sugarcane-leaf-disease-dataset.zip -d data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data_root = \"data\"\n",
    "images_dir = os.path.join(data_root, \"images\")\n",
    "\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for subfolder in os.listdir(data_root):\n",
    "    subfolder_path = os.path.join(data_root, subfolder)\n",
    "    \n",
    "    if os.path.isdir(subfolder_path) and subfolder != \"images\":\n",
    "        for image in os.listdir(subfolder_path):\n",
    "            old_image_path = os.path.join(subfolder_path, image)\n",
    "            \n",
    "            if os.path.isfile(old_image_path):\n",
    "                new_image_path = os.path.join(images_dir, image)\n",
    "                \n",
    "                if os.path.exists(new_image_path):\n",
    "                    base, ext = os.path.splitext(image)\n",
    "                    counter = 1\n",
    "                    while os.path.exists(new_image_path):\n",
    "                        new_image_path = os.path.join(images_dir, f\"{base}_{counter}{ext}\")\n",
    "                        counter += 1\n",
    "                \n",
    "                shutil.move(old_image_path, new_image_path)\n",
    "\n",
    "                dataset.append({\"image_path\": new_image_path, \"label\": subfolder})\n",
    "\n",
    "        os.rmdir(subfolder_path)\n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "df = df.rename(columns={'image_path':'image_id'})\n",
    "df[\"image_id\"] = df[\"image_id\"].str.replace(\"data/images/\", \"\", regex=False)\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])\n",
    "\n",
    "df.to_csv(os.path.join(data_root, \"dataset.csv\"), index=False)\n",
    "\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the dataset again: \n",
    "# import pandas as pd\n",
    "# df = pd.read_csv('/workspace/data/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((448, 448)),  # Resize to input size of MaiaNet\n",
    "        transforms.RandomHorizontalFlip(p=0.5),  # Horizontal flipping\n",
    "        transforms.RandomVerticalFlip(p=0.5),  # Vertical flipping\n",
    "        transforms.ToTensor(),  # Convert to tensor before adding noise\n",
    "        transforms.Lambda(lambda x: x + torch.randn_like(x) * 0.05),  # Add Gaussian noise\n",
    "        transforms.Lambda(lambda x: transforms.functional.erase(x, i=0, j=0, h=50, w=50, v=0.0)),  # Add cutout\n",
    "    ]\n",
    ")\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transform):\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.dataframe.iloc[idx][\"image_id\"]\n",
    "        label = self.dataframe.iloc[idx][\"label\"]\n",
    "        image_path = os.path.join(self.image_dir, image_id)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def get_freq_indices(method):\n",
    "    assert method in [\"top1\", \"top2\", \"top4\", \"top8\", \"top16\", \"top32\", \"bot1\", \"bot2\", \"bot4\", \"bot8\", \"bot16\", \"bot32\", \"low1\", \"low2\", \"low4\", \"low8\", \"low16\", \"low32\"]\n",
    "    num_freq = int(method[3:])\n",
    "    if \"top\" in method:\n",
    "        all_top_indices_x = [0, 0, 6, 0, 0, 1, 1, 4, 5, 1, 3, 0, 0, 0, 3, 2, 4, 6, 3, 5, 5, 2, 6, 5, 5, 3, 3, 4, 2, 2, 6, 1]\n",
    "        all_top_indices_y = [0, 1, 0, 5, 2, 0, 2, 0, 0, 6, 0, 4, 6, 3, 5, 2, 6, 3, 3, 3, 5, 1, 1, 2, 4, 2, 1, 1, 3, 0, 5, 3]\n",
    "        mapper_x = all_top_indices_x[:num_freq]\n",
    "        mapper_y = all_top_indices_y[:num_freq]\n",
    "    elif \"low\" in method:\n",
    "        all_low_indices_x = [0, 0, 1, 1, 0, 2, 2, 1, 2, 0, 3, 4, 0, 1, 3, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4]\n",
    "        all_low_indices_y = [0, 1, 0, 1, 2, 0, 1, 2, 2, 3, 0, 0, 4, 3, 1, 5, 4, 3, 2, 1, 0, 6, 5, 4, 3, 2, 1, 0, 6, 5, 4, 3]\n",
    "        mapper_x = all_low_indices_x[:num_freq]\n",
    "        mapper_y = all_low_indices_y[:num_freq]\n",
    "    elif \"bot\" in method:\n",
    "        all_bot_indices_x = [6, 1, 3, 3, 2, 4, 1, 2, 4, 4, 5, 1, 4, 6, 2, 5, 6, 1, 6, 2, 2, 4, 3, 3, 5, 5, 6, 2, 5, 5, 3, 6]\n",
    "        all_bot_indices_y = [6, 4, 4, 6, 6, 3, 1, 4, 4, 5, 6, 5, 2, 2, 5, 1, 4, 3, 5, 0, 3, 1, 1, 2, 4, 2, 1, 1, 5, 3, 3, 3]\n",
    "        mapper_x = all_bot_indices_x[:num_freq]\n",
    "        mapper_y = all_bot_indices_y[:num_freq]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return mapper_x, mapper_y\n",
    "\n",
    "\n",
    "class MultiSpectralAttentionLayer(torch.nn.Module):\n",
    "    def __init__(self, channel, dct_h, dct_w, reduction=16, freq_sel_method=\"top16\"):\n",
    "        super(MultiSpectralAttentionLayer, self).__init__()\n",
    "        self.reduction = reduction\n",
    "        self.dct_h = dct_h\n",
    "        self.dct_w = dct_w\n",
    "\n",
    "        mapper_x, mapper_y = get_freq_indices(freq_sel_method)\n",
    "        self.num_split = len(mapper_x)\n",
    "        mapper_x = [temp_x * (dct_h // 7) for temp_x in mapper_x]\n",
    "        mapper_y = [temp_y * (dct_w // 7) for temp_y in mapper_y]\n",
    "\n",
    "        self.dct_layer = MultiSpectralDCTLayer(dct_h, dct_w, mapper_x, mapper_y, channel)\n",
    "        self.fc = nn.Sequential(nn.Linear(channel, channel // reduction, bias=False), nn.ReLU(), nn.Linear(channel // reduction, channel, bias=False), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        n, c, h, w = x.shape\n",
    "        x_pooled = x\n",
    "        if h != self.dct_h or w != self.dct_w:\n",
    "            x_pooled = torch.nn.functional.adaptive_avg_pool2d(x, (self.dct_h, self.dct_w))\n",
    "        y = self.dct_layer(x_pooled)\n",
    "\n",
    "        y = self.fc(y).view(n, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class MultiSpectralDCTLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Generate dct filters\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, height, width, mapper_x, mapper_y, channel):\n",
    "        super(MultiSpectralDCTLayer, self).__init__()\n",
    "\n",
    "        assert len(mapper_x) == len(mapper_y)\n",
    "        assert channel % len(mapper_x) == 0\n",
    "\n",
    "        self.num_freq = len(mapper_x)\n",
    "\n",
    "        # fixed DCT init\n",
    "        self.register_buffer(\"weight\", self.get_dct_filter(height, width, mapper_x, mapper_y, channel))\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 4, \"x must been 4 dimensions, but got \" + str(len(x.shape))\n",
    "        # n, c, h, w = x.shape\n",
    "\n",
    "        x = x * self.weight\n",
    "\n",
    "        result = torch.sum(x, dim=[2, 3])\n",
    "        return result\n",
    "\n",
    "    def build_filter(self, pos, freq, POS):\n",
    "        result = math.cos(math.pi * freq * (pos + 0.5) / POS) / math.sqrt(POS)\n",
    "        if freq == 0:\n",
    "            return result\n",
    "        else:\n",
    "            return result * math.sqrt(2)\n",
    "\n",
    "    def get_dct_filter(self, tile_size_x, tile_size_y, mapper_x, mapper_y, channel):\n",
    "        dct_filter = torch.zeros(channel, tile_size_x, tile_size_y)\n",
    "\n",
    "        c_part = channel // len(mapper_x)\n",
    "\n",
    "        for i, (u_x, v_y) in enumerate(zip(mapper_x, mapper_y)):\n",
    "            for t_x in range(tile_size_x):\n",
    "                for t_y in range(tile_size_y):\n",
    "                    dct_filter[i * c_part : (i + 1) * c_part, t_x, t_y] = self.build_filter(t_x, u_x, tile_size_x) * self.build_filter(t_y, v_y, tile_size_y)\n",
    "\n",
    "        return dct_filter\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    # return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "    # resnet101\n",
    "    return\n",
    "\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(nn.Linear(channel, channel // reduction, bias=False), nn.ReLU(), nn.Linear(channel // reduction, channel, bias=False), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class MaiaNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MaiaNet, self).__init__()\n",
    "        self.head = HeadBlock(3, 64)  # Input: 448×448×3 -> 112×112×64\n",
    "        self.anti_aliasing_1 = AntiAliasingBlock(64, 64, downsample=False)  # 112×112×64 -> 112×112×64\n",
    "        self.maia_1 = MaiaBlock(64, 256)  # 112×112×64 -> 112×112×256\n",
    "        self.anti_aliasing_2 = AntiAliasingBlock(256, 512, downsample=True)  # 112×112×256 -> 56×56×512\n",
    "        self.maia_2 = MaiaBlock(512, 512)  # 56×56×512 -> 56×56×512\n",
    "        self.anti_aliasing_3 = AntiAliasingBlock(512, 1024, downsample=True)  # 56×56×512 -> 28×28×1024\n",
    "        self.maia_3 = MaiaBlock(1024, 1024)  # 28×28×1024 -> 28×28×1024\n",
    "        self.maia_4 = MaiaBlock(1024, 2048, downsample=True)  # 14×14×2048 -> 14×14×2048\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))  # Converts 14x14x2048 to 1x1x2048\n",
    "        self.fc = nn.Linear(2048, num_classes)  # Fully connected layer (2048 -> num_classes)\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        if verbose:\n",
    "            print(\"Input:\", x.shape)\n",
    "        x = self.head(x)\n",
    "        if verbose:\n",
    "            print(\"Head:\", x.shape)\n",
    "        x = self.anti_aliasing_1(x)\n",
    "        if verbose:\n",
    "            print(\"Anti-aliasing 1:\", x.shape)\n",
    "        x = self.maia_1(x)\n",
    "        if verbose:\n",
    "            print(\"MAIA 1:\", x.shape)\n",
    "        x = self.anti_aliasing_2(x)\n",
    "        if verbose:\n",
    "            print(\"Anti-aliasing 2:\", x.shape)\n",
    "        x = self.maia_2(x)\n",
    "        if verbose:\n",
    "            print(\"MAIA 2:\", x.shape)\n",
    "        x = self.anti_aliasing_3(x)\n",
    "        if verbose:\n",
    "            print(\"Anti-aliasing 3:\", x.shape)\n",
    "        x = self.maia_3(x)\n",
    "        if verbose:\n",
    "            print(\"MAIA 3:\", x.shape)\n",
    "        x = self.maia_4(x)\n",
    "        if verbose:\n",
    "            print(\"MAIA 4:\", x.shape)\n",
    "\n",
    "        x = self.global_pool(x)  # Shape: (batch_size, 2048, 1, 1)\n",
    "        x = torch.flatten(x, 1)  # Shape: (batch_size, 2048)\n",
    "        x = self.fc(x)  # Shape: (batch_size, num_classes)\n",
    "        return x\n",
    "\n",
    "\n",
    "class HeadBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(HeadBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=7, padding=3, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(MultiAttention, self).__init__()\n",
    "\n",
    "        # https://github.com/hujie-frank/SENet/blob/master/README.md\n",
    "        self.se = SELayer(in_channels, reduction=16)\n",
    "\n",
    "        # https://github.com/cfzd/FcaNet/blob/master/model/fcanet.py\n",
    "        self.fca = MultiSpectralAttentionLayer(in_channels, 7, 7, reduction=16, freq_sel_method=\"top16\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.se(x)\n",
    "        x = self.fca(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AntiAliasingBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample=True):\n",
    "        super(AntiAliasingBlock, self).__init__()\n",
    "\n",
    "        self.downsample = downsample\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.down_conversion = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, groups=out_channels),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        stride = 2 if self.downsample else 1\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "        self.ma = MultiAttention(out_channels)\n",
    "        self.ibn = nn.InstanceNorm2d(out_channels)\n",
    "\n",
    "        self.residual_conv = None\n",
    "        if in_channels != out_channels or downsample:\n",
    "            self.residual_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.residual_conv = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block1(x)\n",
    "        out = self.down_conversion(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.ma(out)\n",
    "        if self.residual_conv:\n",
    "            x = self.residual_conv(x)\n",
    "        out = out + x\n",
    "        out = self.ibn(out)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MaiaBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample=False):\n",
    "        super(MaiaBlock, self).__init__()\n",
    "\n",
    "        stride = 2 if downsample else 1\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.ma = MultiAttention(out_channels)\n",
    "        self.ibn = nn.InstanceNorm2d(out_channels)\n",
    "\n",
    "        if in_channels != out_channels or downsample:\n",
    "            self.residual_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.residual_conv = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.ma(out)\n",
    "\n",
    "        if self.residual_conv:\n",
    "            x = self.residual_conv(x)\n",
    "        out = out + x\n",
    "        out = self.ibn(out)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, test_loader=None, lr=0.2, num_epochs=80, batch_size=16, scheduler=True):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = model.to(self.device)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.num_epochs = num_epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # add L2 regularization to the optimizer\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=self.lr, momentum=0.9, weight_decay=1e-5)\n",
    "        self.scheduler = ExponentialLR(self.optimizer, gamma=0.96) if scheduler else None\n",
    "        self.criterion = nn.CrossEntropyLoss().to(self.device)\n",
    "\n",
    "        self.best_val_loss = float(\"inf\")\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        pbar = tqdm(self.train_loader, desc=f\"Epoch {epoch + 1}/{self.num_epochs}\")\n",
    "\n",
    "        for images, labels in pbar:\n",
    "            images = images.to(self.device, non_blocking=True)\n",
    "            labels = labels.to(self.device, non_blocking=True)\n",
    "\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "            del outputs, loss\n",
    "\n",
    "        if self.scheduler is not None:\n",
    "            self.scheduler.step()\n",
    "\n",
    "        return total_loss / len(self.train_loader)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        for images, labels in self.val_loader:\n",
    "            images = images.to(self.device, non_blocking=True)\n",
    "            labels = labels.to(self.device, non_blocking=True)\n",
    "\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            del outputs, loss\n",
    "\n",
    "        avg_loss = total_loss / len(self.val_loader.dataset)\n",
    "        metrics = self.calculate_metrics(all_preds, all_labels)\n",
    "\n",
    "        return avg_loss, metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_metrics(predictions, labels):\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\", zero_division=0)\n",
    "        return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "    def print_metrics(self, metrics, phase, epoch=None, train_loss=None, test_loss=None, val_loss=None, filename=\"metrics_log.txt\"):\n",
    "        log_entry = [f\"\\n{phase} Metrics:\", \"-\" * 50]\n",
    "        if epoch == 1:\n",
    "            log_entry.append(f\"Running experiment with batch_size={self.batch_size}, lr={self.lr}\")\n",
    "        if epoch is not None:\n",
    "            log_entry.append(f\"Epoch: {epoch}\")\n",
    "        if train_loss is not None:\n",
    "            log_entry.append(f\"Train Loss: {train_loss:.4f}\")\n",
    "        if test_loss is not None:\n",
    "            log_entry.append(f\"Test Loss: {test_loss:.4f}\")\n",
    "        if val_loss is not None:\n",
    "            log_entry.append(f\"Validation Loss: {val_loss:.4f}\")\n",
    "        for metric, value in metrics.items():\n",
    "            log_entry.append(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "        log_entry.append(\"-\" * 50)\n",
    "\n",
    "        log_text = \"\\n\".join(log_entry)\n",
    "        print(log_text)\n",
    "\n",
    "        with open(filename, \"a\") as f:\n",
    "            f.write(log_text + \"\\n\")\n",
    "\n",
    "    def train(self):\n",
    "        try:\n",
    "            for epoch in range(self.num_epochs):\n",
    "                train_loss = self.train_epoch(epoch)\n",
    "                val_loss, val_metrics = self.validate()\n",
    "\n",
    "                self.print_metrics(val_metrics, \"Train\", epoch, train_loss, val_loss)\n",
    "\n",
    "                if val_loss < self.best_val_loss:\n",
    "                    self.best_val_loss = val_loss\n",
    "                    self.best_model_state = {k: v.cpu() for k, v in self.model.state_dict().items()}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Training interrupted: {str(e)}\")\n",
    "            if self.best_model_state is not None:\n",
    "                torch.save(self.best_model_state, \"interrupted_model.pt\")\n",
    "\n",
    "    def test(self):\n",
    "        if self.best_model_state is not None:\n",
    "            self.model.load_state_dict({k: v.to(self.device) for k, v in self.best_model_state.items()})\n",
    "        test_loss, test_metrics = self.validate()\n",
    "        self.print_metrics(test_metrics, \"Test\", test_loss=test_loss)\n",
    "        return test_loss, test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [32, 16, 12, 8, 4]\n",
    "lrs = [1e-4, 1e-5, 2e-5]\n",
    "\n",
    "# def run_experiment(batch_size, lr):\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "#     test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#     model = MaiaNet(num_classes)\n",
    "#     trainer = Trainer(model, train_loader, val_loader, test_loader, lr, num_epochs, batch_size= batch_size)\n",
    "\n",
    "#     trainer.train()\n",
    "#     trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "num_folds = 7\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "num_classes = 5\n",
    "path = '/workspace/data/images'\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
    "\n",
    "test_dataset = Dataset(test_df, path, transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "fold_results = {}\n",
    "\n",
    "image_paths = df[\"image_id\"].values\n",
    "labels = df[\"label\"].values\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(image_paths, labels)):\n",
    "    print(f\"\\n🌀 Fold {fold+1} ------------------------\")\n",
    "\n",
    "    train_subset = Dataset(train_df.iloc[train_idx], path, transform)\n",
    "    val_subset = Dataset(train_df.iloc[val_idx], path, transform)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    \n",
    "    model = MaiaNet(num_classes)\n",
    "    trainer = Trainer(model, train_loader, val_loader, test_loader=test_loader, lr=learning_rate, num_epochs=num_epochs, batch_size= batch_size)\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "    fold_metrics = trainer.test()\n",
    "    fold_results[fold] = fold_metrics\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

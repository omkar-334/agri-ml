{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f84097-2600-4660-9d34-f43e81bbc45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q Visualization.zip -d vizdata # download the zip file from email\n",
    "# !pip install --upgrade pip setuptools\n",
    "# !pip install --use-pep517 torch torchvision pytorch-gradcam matplotlib lime timm grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f88a220-5390-446a-9030-b91239d9b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from utils import download, suppress_stdout_stderr\n",
    "\n",
    "model_files = [\n",
    "    \"maianet_nirmal.pth\",\n",
    "    \"soyatrans_nirmal.pth\",\n",
    "    \"tswinf_nirmalsankana.pth\",\n",
    "    \"maianet_pungliya.pth\",\n",
    "    \"soyatrans_pungliya.pth\",\n",
    "    \"tswinf_pungliyavithika.pth\",\n",
    "    \"maianet_mendeley.pth\",\n",
    "    \"soyatrans_mendeley.pth\",\n",
    "    \"tswinf_mendeley.pth\",\n",
    "]\n",
    "\n",
    "download(model_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14c4de-d82a-4739-9257-fa04222d24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "# nirmalsankana\n",
    "# {'Healthy': 0, 'Mosaic': 1, 'RedRot': 2, 'Rust': 3, 'Yellow': 4}\n",
    "\n",
    "# pungliyavithika\n",
    "# {'Healthy': 0, 'RedRot': 1, 'RedRust': 2}\n",
    "\n",
    "vdata = datasets.ImageFolder(\"vizdata/Visualization/pungliyavithika\", transform=transform)\n",
    "ndata = datasets.ImageFolder(\"vizdata/Visualization/nirmalsankana\", transform=transform)\n",
    "mdata = datasets.ImageFolder(\"vizdata/Visualization/mendeley\", transform=transform)\n",
    "\n",
    "\n",
    "def match_dataset(model_name):\n",
    "    if \"nirmal\" in model_name:\n",
    "        dataset = ndata\n",
    "    elif \"mendeley\" in model_name:\n",
    "        dataset = mdata\n",
    "    else:\n",
    "        dataset = vdata\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe1d8e5-4627-48a2-a104-533c0bed9467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubuntu/myenv/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maianet_mendeley.pth loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from build import build_model\n",
    "from config import get_config\n",
    "\n",
    "from maianet import MaiaNet\n",
    "from soyatrans import SoyaTrans\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_objects = [MaiaNet(5), SoyaTrans(5), build_model(get_config(), 5), MaiaNet(3), SoyaTrans(3), build_model(get_config(), 5), MaiaNet(11), SoyaTrans(11), build_model(get_config(), 11)]\n",
    "\n",
    "\n",
    "def instance(model, file):\n",
    "    checkpoint = torch.load(f\"models/{file}\")\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    print(f\"{file} loaded\")\n",
    "\n",
    "    if \"maianet\" in file:\n",
    "        target_layer = [model.maia_4.conv3[0]]\n",
    "    elif \"soyatrans\" in file:\n",
    "        target_layer = [model.stage1.downsample]\n",
    "    elif \"tswinf\" in file:\n",
    "        # target_layer = [model.stage4[0].attns[0].get_v]\n",
    "        target_layer = [model.LCA.conv1[0]]\n",
    "    return model, target_layer\n",
    "\n",
    "\n",
    "models = {file: instance(model, file) for file, model in zip(model_files, model_objects)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf787cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam import (\n",
    "    GradCAM,\n",
    "    GradCAMPlusPlus,\n",
    "    ScoreCAM,  # Needed for isinstance check\n",
    ")\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def tensor_to_rgb_image(tensor):\n",
    "    img = tensor.clone().detach().cpu()\n",
    "    img = img * 0.5 + 0.5  # reverse normalization\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    img = np.clip(img, 0, 1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def plot(model, image, image_path, class_index, cams, output_dir=\"data/cam_outputs\"):\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = image.unsqueeze(0).to(device)\n",
    "    rgb_img = tensor_to_rgb_image(image)\n",
    "\n",
    "    target = [ClassifierOutputTarget(class_index)]\n",
    "\n",
    "    # Save original image\n",
    "    original_path = os.path.join(output_dir, f\"{base_name}_original.jpg\")\n",
    "    Image.fromarray((rgb_img * 255).astype(np.uint8)).save(original_path)\n",
    "\n",
    "    for name, cam_method in cams.items():\n",
    "        if isinstance(cam_method, ScoreCAM):\n",
    "            with torch.no_grad():\n",
    "                grayscale_cam = cam_method(input_tensor=input_tensor, targets=target)[0]\n",
    "        else:\n",
    "            grayscale_cam = cam_method(input_tensor=input_tensor, targets=target)[0]\n",
    "\n",
    "        cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "        save_path = os.path.join(output_dir, f\"{base_name}_{name}.jpg\")\n",
    "        Image.fromarray(cam_image).save(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591644f5-0827-4382-98a9-dfaae65a240b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: maianet_mendeley.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "maianet_mendeley.pth: 100%|██████████| 165/165 [02:21<00:00,  1.17it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "for model_name, model_item in models.items():\n",
    "\n",
    "    model, target_layers = model_item\n",
    "    dataset = match_dataset(model_name)\n",
    "\n",
    "    model = model.cuda() if torch.cuda.is_available() else model.cpu()\n",
    "    model.eval()\n",
    "\n",
    "    # Create CAM methods only once per model\n",
    "    cams = {\n",
    "        \"Grad-CAM\": GradCAM(model=model, target_layers=target_layers),\n",
    "        \"Grad-CAM++\": GradCAMPlusPlus(model=model, target_layers=target_layers),\n",
    "        \"Score-CAM\": ScoreCAM(model=model, target_layers=target_layers),\n",
    "    }\n",
    "\n",
    "    with tqdm(total=len(dataset), desc=f\"{model_name}\", leave=True) as pbar:\n",
    "        for idx in range(len(dataset)):\n",
    "            image, label = dataset[idx]\n",
    "            image_path, _ = dataset.imgs[idx]\n",
    "\n",
    "            # Suppress plot outputs\n",
    "            with suppress_stdout_stderr():\n",
    "                base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "                output_dir = f\"output/{model_name}\"\n",
    "                original_path = os.path.join(output_dir, f\"{base_name}_original.jpg\")\n",
    "\n",
    "                if not os.path.isfile(original_path):\n",
    "                    # Plot only if original image is not already saved\n",
    "                    plot(model, image, image_path, label, cams, output_dir=f\"output/{model_name}\")\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Clean up\n",
    "    del model, cams\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9417db-485d-4bc3-9f4a-82f836046584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vizkernerl",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
